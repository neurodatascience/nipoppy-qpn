{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to prototype REDCap API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(url, query, logger=None):\n",
    "    r = requests.post(url, data=query, verify=False)\n",
    "    http_status = str(r.status_code)\n",
    "    print(f'HTTP Status: {http_status}')\n",
    "\n",
    "    if http_status == \"200\":\n",
    "        query_results = r.json()\n",
    "        query_df = pd.DataFrame(query_results)\n",
    "\n",
    "    else:\n",
    "        print(f\"RedCap API request Failed with HTTP Status: {http_status}\")\n",
    "        query_df = None\n",
    "        \n",
    "    return query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/nikhil/projects/Parkinsons/qpn/\"\n",
    "\n",
    "# Current nipoppy manifest\n",
    "release_dir = f\"{DATASET_ROOT}/releases/\"\n",
    "current_release = \"Jan_2024\"\n",
    "current_nipoppy_manifest_csv = f\"{release_dir}{current_release}/tabular/manifest.csv\"\n",
    "legacy_qpn_imaging_codes_xlsx = f\"{release_dir}{current_release}/tabular/recruitment/QPN_Imaging_Codes.xlsx\"\n",
    "\n",
    "# Legacy DoB (Roozbeh)\n",
    "legacy_participants_DOB = f\"{release_dir}{current_release}/tabular/recruitment/legacy_freeze/QPN-DOB-90subjects.csv\"\n",
    "# legacy_participants_DOB_codes = f\"{DATASET_ROOT}/tabular/recruitment/legacy_freeze/QPN-DOB-codes.csv\"\n",
    "\n",
    "# Redcap report (Sarah)\n",
    "# redcap_report_csv = f\"{release_dir}{current_release}/tabular/assessments/COPN-MRIDataReport2023110_DATA_LABELS_2024-01-10_1004.csv\"\n",
    "redcap_report_csv = f\"{release_dir}{current_release}/tabular/redcap/COPN-MRIDataReport2023110_DATA_LABELS_2024-02-19_0851.csv\"\n",
    "\n",
    "# MRI dates (dicom header)\n",
    "MRI_dates_csv = f\"{DATASET_ROOT}/scratch/mri_dates_sanity_check.csv\"\n",
    "MRI_acq_data_csv = f\"{release_dir}{current_release}/tabular/recruitment/MRI_acqdata.csv\"\n",
    "\n",
    "# Sharp lab Neurocog dates\n",
    "neurocog_date_xlsx = f\"{release_dir}{current_release}/tabular/recruitment/Sharp_QPN_List.xlsx\"\n",
    "revised_neurocog_date_xlsx = f\"{release_dir}{current_release}/tabular/recruitment/Sharp_QPN_List_revised.xlsx\"\n",
    "\n",
    "# Local Redcap query dict - avoid frequent API calls\n",
    "query_dict_pkl = f\"{release_dir}{current_release}/tabular/redcap/redcap_query_dict.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/nikhil/projects/Parkinsons/qpn//releases/Jan_2024/tabular/manifest.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m session_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mses-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m session_id_list]\n\u001b[1;32m      5\u001b[0m manifest_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparticipant_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m current_nipoppy_manifest_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_nipoppy_manifest_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m current_nipoppy_manifest_df \u001b[38;5;241m=\u001b[39m current_nipoppy_manifest_df[current_nipoppy_manifest_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(visit_list)]\n\u001b[1;32m      9\u001b[0m current_nipoppy_manifest_df \u001b[38;5;241m=\u001b[39m current_nipoppy_manifest_df[current_nipoppy_manifest_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msession\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39misin(session_list)]\n",
      "File \u001b[0;32m~/projects/my_venvs/nipoppy/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/my_venvs/nipoppy/lib/python3.10/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/projects/my_venvs/nipoppy/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/my_venvs/nipoppy/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/projects/my_venvs/nipoppy/lib/python3.10/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/nikhil/projects/Parkinsons/qpn//releases/Jan_2024/tabular/manifest.csv'"
     ]
    }
   ],
   "source": [
    "visit_list = [\"MRI_v1\"] \n",
    "session_id_list = [\"01\"]\n",
    "session_list = [f\"ses-{idx}\" for idx in session_id_list]\n",
    "\n",
    "manifest_cols = [\"participant_id\", \"visit\", \"session\"]\n",
    "\n",
    "current_nipoppy_manifest_df = pd.read_csv(current_nipoppy_manifest_csv)\n",
    "current_nipoppy_manifest_df = current_nipoppy_manifest_df[current_nipoppy_manifest_df[\"visit\"].isin(visit_list)]\n",
    "current_nipoppy_manifest_df = current_nipoppy_manifest_df[current_nipoppy_manifest_df[\"session\"].isin(session_list)]\n",
    "current_nipoppy_manifest_df = current_nipoppy_manifest_df[manifest_cols]\n",
    "current_nipoppy_manifest_df[\"participant_id\"] = current_nipoppy_manifest_df[\"participant_id\"].str.upper()\n",
    "nipoppy_participants = current_nipoppy_manifest_df[\"participant_id\"].unique()\n",
    "n_participants = len(nipoppy_participants)\n",
    "print(f\"n_participants: {n_participants}\")\n",
    "current_nipoppy_manifest_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legacy demographics and visit dates (from an older excel spreadhsheet)\n",
    "- Using this while REDCap is getting updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_name = \"recruit_manifest\"\n",
    "usecols = [\"participant_id\", \"group\", \"sex\", \"dob\", \"visit_01\"]\n",
    "legacy_recruit_df = pd.read_excel(legacy_qpn_imaging_codes_xlsx, sheet_name=sheet_name, engine='openpyxl', usecols=usecols)\n",
    "legacy_recruit_df[\"participant_id\"] = legacy_recruit_df[\"participant_id\"].str.upper()\n",
    "\n",
    "legacy_col_dict = {\"group\": \"legacy_group\", \"sex\":\"legacy_sex\", \"dob\":\"legacy_dob\", \"visit_01\": \"legacy_date_MRI\"}\n",
    "legacy_recruit_df = legacy_recruit_df.rename(columns=legacy_col_dict)\n",
    "\n",
    "legacy_participants = legacy_recruit_df[\"participant_id\"].unique()\n",
    "n_legacy_participants = len(legacy_participants)\n",
    "print(f\"n_legacy_participants: {n_legacy_participants}\")\n",
    "\n",
    "legacy_recruit_df[\"legacy_dob\"] = pd.to_datetime(legacy_recruit_df[\"legacy_dob\"], errors=\"coerce\", dayfirst=True)\n",
    "legacy_recruit_df[\"legacy_date_MRI\"] = pd.to_datetime(legacy_recruit_df[\"legacy_date_MRI\"], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "# calculate age at MRI_V01\n",
    "legacy_recruit_df[\"legacy_age_MRI\"] = legacy_recruit_df[\"legacy_date_MRI\"] - legacy_recruit_df[\"legacy_dob\"]\n",
    "legacy_recruit_df[\"legacy_age_MRI\"] = np.round(legacy_recruit_df[\"legacy_age_MRI\"].dt.days / 365.25, 2)\n",
    "\n",
    "legacy_recruit_df[\"visit_id\"] = \"MRI_v1\"\n",
    "legacy_recruit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add legacy DoB (from frozen legacy DoB csv for participants not yet consented to be in RedCAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOB_col = \"Date of Birth/Date de naissance\"\n",
    "cross_ref_col = \"Reference number\"\n",
    "record_col = \"Record ID\"\n",
    "\n",
    "legacy_DOB = pd.read_csv(legacy_participants_DOB)\n",
    "legacy_DOB = legacy_DOB.rename(columns={ DOB_col:\"dob\", record_col:\"participant_id\"})\n",
    "\n",
    "# legacy_DOB_codes = pd.read_csv(legacy_participants_DOB_codes)\n",
    "# legacy_DOB_codes = legacy_DOB_codes.rename(columns={record_col:\"participant_id\"})\n",
    "# legacy_DOB = pd.merge(legacy_DOB_codes, legacy_DOB, how=\"left\", on=cross_ref_col).drop(columns=[cross_ref_col])\n",
    "\n",
    "legacy_DOB[\"dob\"] = pd.to_datetime(legacy_DOB[\"dob\"], errors=\"coerce\", dayfirst=False)\n",
    "legacy_DOB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add MRI dates from Suivi_RPQ and dicom headers to the legacy df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI_dates_df = pd.read_csv(MRI_dates_csv)\n",
    "n_mri_dates_participants = len(MRI_dates_df[\"participant_id\"].unique())\n",
    "print(f\"n_mri_dates_participants: {n_mri_dates_participants}\")\n",
    "\n",
    "MRI_dates_df = MRI_dates_df[MRI_dates_df[\"visit_id\"]==\"MRI_v1\"][[\"participant_id\",\"visit_id\",\"suivi_MRI_date\",\"dicom_date\"]]\n",
    "MRI_dates_df[\"suivi_MRI_date\"] = pd.to_datetime(MRI_dates_df[\"suivi_MRI_date\"], errors=\"coerce\", dayfirst=False)\n",
    "MRI_dates_df[\"dicom_date\"] = pd.to_datetime(MRI_dates_df[\"dicom_date\"], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "legacy_recruit_df = pd.merge(MRI_dates_df, legacy_recruit_df, on=[\"participant_id\",\"visit_id\"], how=\"left\")\n",
    "\n",
    "legacy_recruit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_recruit_df[legacy_recruit_df[\"participant_id\"]==\"PD01306\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add MRI acq dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI_acq_data_df = pd.read_csv(MRI_acq_data_csv).drop(columns=[\"index\",\"participant_dicom_dir\"])\n",
    "MRI_acq_data_df.loc[MRI_acq_data_df[\"session\"]==\"ses-01\", \"visit_id\"] = \"MRI_v1\"\n",
    "MRI_acq_data_df.loc[MRI_acq_data_df[\"session\"]==\"ses-02\", \"visit_id\"] = \"MRI_v2\"\n",
    "\n",
    "n_ses1 = len(MRI_acq_data_df[(MRI_acq_data_df[\"visit_id\"]==\"MRI_v1\") & (~MRI_acq_data_df[\"scanner_acq_date\"].isna())][\"participant_id\"].unique())\n",
    "n_ses2 = len(MRI_acq_data_df[(MRI_acq_data_df[\"visit_id\"]==\"MRI_v2\") & (~MRI_acq_data_df[\"scanner_acq_date\"].isna()) ][\"participant_id\"].unique())\n",
    "print(f\"n_ses1: {n_ses1}, n_ses2: {n_ses2}\")\n",
    "\n",
    "MRI_acq_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge legacy recruit data with MRI acquisition dates\n",
    "legacy_recruit_df = pd.merge(MRI_acq_data_df, legacy_recruit_df, on=[\"participant_id\",\"visit_id\"], how=\"left\")\n",
    "legacy_recruit_df[\"scanner_acq_date\"] = pd.to_datetime(legacy_recruit_df[\"scanner_acq_date\"], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "n_ses1 = len(legacy_recruit_df[legacy_recruit_df[\"visit_id\"]==\"MRI_v1\"][\"participant_id\"].unique())\n",
    "n_ses2 = len(legacy_recruit_df[legacy_recruit_df[\"visit_id\"]==\"MRI_v2\"][\"participant_id\"].unique())\n",
    "print(f\"n_ses1: {n_ses1}, n_ses2: {n_ses2}\")\n",
    "\n",
    "legacy_recruit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redcap config\n",
    "QPN specific reports:\n",
    "['QPN participants', 'External QPN (June 2021)', 'Demographic QPN', 'QPN-Clinical questionnaire', 'QPN sex', 'Diagnosis QPN', 'MoCA-MDS-UPDRS part 3', 'Victoria - Weston Project', 'MotorAndNon-Motor', 'MoCA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_config_json = f\"{DATASET_ROOT}/proc/.redcap.json\"\n",
    "redcap_config = json.load(open(redcap_config_json))\n",
    "url = redcap_config[\"url\"]\n",
    "redcap_reports = list(redcap_config[\"queries\"].keys())\n",
    "n_redcap_reports = len(redcap_reports)\n",
    "print(f\"redcap_reports ({n_redcap_reports}): {redcap_reports}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_local_redcap = True\n",
    "\n",
    "query_dict = {}\n",
    "redcap_participants = []\n",
    "\n",
    "if load_local_redcap:\n",
    "    print(f\"Loading redcap data from {query_dict_pkl}...\")\n",
    "    with open(query_dict_pkl, 'rb') as fp:\n",
    "        query_dict = pickle.load(fp)\n",
    "\n",
    "    for query_label in query_dict.keys():\n",
    "        query_df = query_dict[query_label]\n",
    "        _participants = query_df[\"record_id\"].unique()\n",
    "        redcap_participants.extend(_participants)\n",
    "        n_participants = len(redcap_participants)\n",
    "        print(f\"Loaded {n_participants} participants from {query_label}...\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(f\"Fetching redcap data from {url}...\")\n",
    "\n",
    "    api_report_list = [\"Demographic QPN\",\"Victoria - Weston Project\",\"QPN MoCA-UPDRS-Neuropsy data_Sarah\"]\n",
    "    for query_label in redcap_reports:\n",
    "\n",
    "        if query_label in api_report_list:\n",
    "            query = redcap_config[\"queries\"][query_label]\n",
    "\n",
    "            # run query\n",
    "            print(f\"Running query {query_label}...\")\n",
    "            time.sleep(1)\n",
    "            query_df = api_call(url, query, logger=None)\n",
    "            query_df[\"record_id\"] = query_df[\"record_id\"].str.upper()\n",
    "\n",
    "            # get the list of participants\n",
    "            _participants = query_df[\"record_id\"].unique()\n",
    "            redcap_participants.extend(_participants)\n",
    "            n_participants = len(redcap_participants)\n",
    "\n",
    "            # get the list of redcap events\n",
    "            redcap_events = query_df[\"redcap_event_name\"].unique()\n",
    "            n_events = len(redcap_events)\n",
    "\n",
    "            print(f\"Fetched {n_participants} participants and {n_events} event_ids: {redcap_events}\")\n",
    "\n",
    "            query_dict[query_label] = query_df.copy()\n",
    "        \n",
    "        with open(query_dict_pkl, 'wb') as fp:\n",
    "            pickle.dump(query_dict, fp)\n",
    "\n",
    "redcap_participants = list(set(redcap_participants))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_dict[\"QPN MoCA-UPDRS-Neuropsy data_Sarah\"].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_cols = query_dict[\"QPN MoCA-UPDRS-Neuropsy data_Sarah\"].columns\n",
    "substr = \"dob\"\n",
    "res = [i for i in redcap_cols if substr in i]\n",
    "query_df[res].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df[\"record_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redcap report\n",
    "This comes from Sarah with DoB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_report_df = pd.read_csv(redcap_report_csv)\n",
    "\n",
    "demo_col_dict = {\"Record ID:\": \"participant_id\", \"Event Name\": \"redcap_event_name\", \n",
    "                 \"Enrolment Group:\": \"group\", \"Date of Birth\":\"dob\", \"1. Sex\": \"sex\", \n",
    "                 \"Date of MoCA administration\": \"moca_date\",\"MDS-UPDRS Date\":\"updrs_date\",\n",
    "                 \"Neuropsycholgical Test Date:\": \"neuropsy_date\"}\n",
    "\n",
    "redcap_report_df = redcap_report_df[list(demo_col_dict.keys())].rename(columns=demo_col_dict)\n",
    "\n",
    "redcap_report_df[\"participant_id\"] = redcap_report_df[\"participant_id\"].str.upper()\n",
    "redcap_report_df[\"sex\"] = redcap_report_df[\"sex\"].replace({\"Male/Masculin\":\"M\", \"Female/Féminin\":\"F\"})\n",
    "\n",
    "redcap_report_participants = redcap_report_df[\"participant_id\"].unique()\n",
    "n_participants = redcap_report_df[\"participant_id\"].nunique()\n",
    "n_events = redcap_report_df[\"redcap_event_name\"].unique()\n",
    "n_DOBs = redcap_report_df[redcap_report_df['dob'].notnull()][\"participant_id\"].nunique()\n",
    "\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "print(f\"Number of events: {n_events}\")\n",
    "\n",
    "print(f\"Number of available DOB: {n_DOBs}\")\n",
    "redcap_report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_report_df[redcap_report_df[\"participant_id\"]==\"PD01306\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add dob from legacy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legacy_dob_participants = legacy_DOB[\"participant_id\"].unique()\n",
    "legacy_dob_participants = set(legacy_dob_participants) & set(redcap_report_df[redcap_report_df[\"dob\"].isna()][\"participant_id\"])\n",
    "\n",
    "print(f\"Number of legacy participants with DOB: {len(legacy_dob_participants)}\")\n",
    "      \n",
    "redcap_report_df[\"dob\"] = pd.to_datetime(redcap_report_df[\"dob\"], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "for p in legacy_dob_participants:\n",
    "    redcap_report_df.loc[(redcap_report_df[\"participant_id\"] == p) & \n",
    "                         (redcap_report_df[\"redcap_event_name\"] == \"Baseline (Arm 1: C-OPN)\"), \n",
    "                         \"dob\"] = legacy_DOB.loc[legacy_DOB[\"participant_id\"]==p,\"dob\"].values[0]\n",
    "    \n",
    "n_DOBs = redcap_report_df[redcap_report_df['dob'].notnull()][\"participant_id\"].nunique()\n",
    "print(f\"Number of available DOB: {n_DOBs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_report_df[redcap_report_df[\"participant_id\"]==\"PD01306\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate ages from dates in the redcap report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_report_df[\"moca_date\"] = pd.to_datetime(redcap_report_df[\"moca_date\"], errors=\"coerce\", dayfirst=False)\n",
    "redcap_report_df[\"updrs_date\"] = pd.to_datetime(redcap_report_df[\"updrs_date\"], errors=\"coerce\", dayfirst=False)\n",
    "redcap_report_df[\"neuropsy_date\"] = pd.to_datetime(redcap_report_df[\"neuropsy_date\"], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "## fill in dob for followup visits\n",
    "dob_df = redcap_report_df[[\"participant_id\",\"dob\"]].copy()\n",
    "# dob_df = dob_df.dropna(subset=\"dob\")\n",
    "redcap_report_df = pd.merge(redcap_report_df.drop(columns=\"dob\"), dob_df, on=\"participant_id\")\n",
    "\n",
    "redcap_report_df[\"age_moca\"] = redcap_report_df[\"moca_date\"] - redcap_report_df[\"dob\"]\n",
    "redcap_report_df[\"age_moca\"] = np.round(redcap_report_df[\"age_moca\"].dt.days / 365.25, 2)\n",
    "\n",
    "redcap_report_df[\"age_updrs\"] = redcap_report_df[\"updrs_date\"] - redcap_report_df[\"dob\"]\n",
    "redcap_report_df[\"age_updrs\"] = np.round(redcap_report_df[\"age_updrs\"].dt.days / 365.25, 2)\n",
    "\n",
    "redcap_report_df[\"age_neuropsy\"] = redcap_report_df[\"neuropsy_date\"] - redcap_report_df[\"dob\"]\n",
    "redcap_report_df[\"age_neuropsy\"] = np.round(redcap_report_df[\"age_neuropsy\"].dt.days / 365.25, 2)\n",
    "\n",
    "redcap_report_participants = redcap_report_df[\"participant_id\"].unique()\n",
    "print(f\"n_redcap_report_df: {len(redcap_report_participants)}\")\n",
    "\n",
    "redcap_report_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Participant tallys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redcap_participants = [p.upper() for p in redcap_participants]\n",
    "\n",
    "print(f\"Number of nipoppy participants: {len(nipoppy_participants)}\")\n",
    "print(f\"Number of legacy participants: {len(legacy_participants)}\")\n",
    "print(f\"Number of redcap participants: {len(redcap_participants)}\")\n",
    "print(f\"Number of redcap report participants: {len(redcap_report_participants)}\")\n",
    "\n",
    "\n",
    "a = set(nipoppy_participants)\n",
    "b = set(legacy_participants)\n",
    "c = set(redcap_participants)\n",
    "d = set(redcap_report_participants)\n",
    "\n",
    "nipoppy_legacy_common_participants = a.intersection(b)\n",
    "n_nipoppy_legacy_common_participants = len(nipoppy_legacy_common_participants)\n",
    "\n",
    "nipoppy_redcap_common_participants = a.intersection(c)\n",
    "n_nipoppy_redcap_common_participants = len(nipoppy_redcap_common_participants)\n",
    "\n",
    "nipoppy_redcap_report_common_participants = a.intersection(d)\n",
    "n_nipoppy_redcap_report_common_participants = len(nipoppy_redcap_report_common_participants)\n",
    "\n",
    "nipoppy_not_in_legacy_participants  = a.difference(b) # nipoppy participants not in the legacy spreadsheets\n",
    "n_nipoppy_not_in_legacy_participants = len(nipoppy_not_in_legacy_participants)\n",
    "\n",
    "nipoppy_not_in_redcap_participants  = a.difference(c) # nipoppy participants not in the redcap yet\n",
    "n_nipoppy_not_in_redcap_participants = len(nipoppy_not_in_redcap_participants)\n",
    "\n",
    "nipoppy_not_in_redcap_report_participants  = a.difference(d) # nipoppy participants not in the redcap report yet\n",
    "n_nipoppy_not_in_redcap_report_participants = len(nipoppy_not_in_redcap_report_participants)\n",
    "\n",
    "missing_nipoppy_participants = a.difference(c).difference(d)\n",
    "n_missing_nipoppy_participants = len(missing_nipoppy_participants)\n",
    "\n",
    "new_redcap_participants  = nipoppy_redcap_common_participants.difference(d) # nipoppy-redcap participants not in the report yet\n",
    "n_new_redcap_participants = len(new_redcap_participants)\n",
    "\n",
    "print(f\"nipoppy-legacy common participants: {n_nipoppy_legacy_common_participants}\")\n",
    "print(f\"nipoppy-redcap common participants: {n_nipoppy_redcap_common_participants}\")\n",
    "print(f\"nipoppy-recdap_report common participants: {n_nipoppy_redcap_report_common_participants}\")\n",
    "\n",
    "print(f\"nipoppy-redcap participants not in the report yet (n={n_new_redcap_participants}): {new_redcap_participants}\")\n",
    "print(f\"missing_nipoppy_participants (n={n_missing_nipoppy_participants}): {missing_nipoppy_participants}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demographics, Dx, and summary clinical scores\n",
    "- `Demographic QPN`\n",
    "    - \"study_visit_age\", \"gender\", \"yrs_education\"\n",
    "        - Note: study visit age will be different for different assessments\n",
    "        - **study_visit_age is not useful since it's self reported at random times**\n",
    "- `Diagnosis QPN` does not have Dx for all participants\n",
    "- `Victoria - Weston Project` (Legend for Determined diagnosis)\n",
    "    - If score = 0, Parkinson's Disease (PD)  \n",
    "    - If score = 1, Progressive Supranuclear Palsy (PSP)  \n",
    "    - If score = 2, Multiple System Atrophy (MSA) \n",
    "    - If score = 3, Corticobasal Syndrome (CBS)  \n",
    "    - If score = 4, Dementia wi1th Lewy Bodies (DLB)  \n",
    "    - If score = 5, Frontotemporal Dementia (FTD)  \n",
    "    - If score = 6, Essential Tremor (ET)  \n",
    "    - If score = 7, REM Sleep Behaviour Disorder (RBD)\n",
    "- `MotorAndNon-Motor` \n",
    "    - summary clinical scores (updrs, moca)\n",
    "    - verify moca column with extra point i.e. `moca_extra_point`\n",
    "- `QPN MoCA-UPDRS-Neuropsy data_Sarah`\n",
    "    - Has additional updrs variables \n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate useful redcap data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_columns = [\"record_id\", \"redcap_event_name\"]\n",
    "\n",
    "demo_cols = [\"gender\", \"yrs_education\"]\n",
    "demo_df = query_dict['Demographic QPN'][index_columns + demo_cols].copy()\n",
    "\n",
    "dx_cols = [\"diagnosis_determined\", \"duration_disease\"]\n",
    "dx_df = query_dict['Victoria - Weston Project'][index_columns + dx_cols]\n",
    "\n",
    "diagnosis_determined_label_map = {\n",
    "    \"0\" : \"PD\",\n",
    "    \"1\" : \"PSP\",\n",
    "    \"2\" : \"MSA\",\n",
    "    \"3\" : \"CBS\", \n",
    "    \"4\" : \"DLB\",\n",
    "    \"5\" : \"FTD\", \n",
    "    \"6\" : \"ET\",\n",
    "    \"7\" : \"RBD\"\n",
    "}\n",
    "dx_df.loc[:,\"diagnosis_determined\"] = dx_df[\"diagnosis_determined\"].astype(str).replace(diagnosis_determined_label_map).copy()\n",
    "\n",
    "updrs_cols = [\"mds_updrs_h_y\", \"updrs_score_part_1\", \"updrs_score_part_2\", \"updrs_score_part_3\", \"updrs_score_part_4\"]\n",
    "moca_cols = ['moca_result'] \n",
    "moca_subscore_cols = ['moca_result_2', 'moca_result_3', 'moca_result_4','moca_result_5', 'moca_result_6', \n",
    "                      'moca_result_7', 'moca_result_8','moca_result_9']\n",
    "\n",
    "score_cols = updrs_cols + moca_cols\n",
    "score_df = query_dict[\"QPN MoCA-UPDRS-Neuropsy data_Sarah\"][index_columns + score_cols].copy()\n",
    "\n",
    "redcap_df = pd.merge(demo_df, dx_df, on=index_columns)\n",
    "redcap_df = pd.merge(score_df, redcap_df, on=index_columns, how=\"left\")\n",
    "\n",
    "redcap_df[\"gender\"] = redcap_df[\"gender\"].replace({\"Male/Masculin\":\"M\", \"Female/Féminin\":\"F\"})\n",
    "\n",
    "n_redcap_common_participants = len(redcap_df[\"record_id\"].unique())\n",
    "print(f\"Found {n_redcap_common_participants} recdap-nipoppy common participants\")\n",
    "\n",
    "print(f\"redcap events: {redcap_df['redcap_event_name'].unique()}\")\n",
    "\n",
    "redcap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_df[redcap_df[\"record_id\"]==\"PD01306\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge MRI, legacy and redcap tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge redcap query df\n",
    "redcap_event_list = ['Baseline (Arm 1: C-OPN)',\n",
    "                     '12 Months Follow-Up/Suivi (Arm 1: C-OPN)', \n",
    "                     '18 Months Follow-Up/Suivi (Arm 1: C-OPN)',\n",
    "                     '24 Months Follow-Up/Suivi (Arm 1: C-OPN)']\n",
    "\n",
    "nipoppy_redcap_df = redcap_df[(redcap_df[\"record_id\"].str.upper().isin(nipoppy_participants)) & \n",
    "                              (redcap_df[\"redcap_event_name\"].isin(redcap_event_list))].copy()\n",
    "\n",
    "n_nipoppy_redcap_participants = len(nipoppy_redcap_df[\"record_id\"].unique())\n",
    "print(f\"n_nipoppy_redcap_participants: {n_nipoppy_redcap_participants}\")\n",
    "               \n",
    "nipoppy_redcap_df = nipoppy_redcap_df.replace(\"\", np.nan)\n",
    "nipoppy_redcap_df = nipoppy_redcap_df.rename(columns={\"record_id\": \"participant_id\"})\n",
    "\n",
    "nipoppy_redcap_df = pd.merge(nipoppy_redcap_df, legacy_recruit_df, on=\"participant_id\", how=\"left\")\n",
    "\n",
    "n_nipoppy_redcap_participants = len(nipoppy_redcap_df[\"participant_id\"].unique())\n",
    "print(f\"n_nipoppy_redcap_participants: {n_nipoppy_redcap_participants}\")\n",
    "\n",
    "redcap_events = nipoppy_redcap_df[\"redcap_event_name\"].unique()\n",
    "print(f\"redcap_events: {redcap_events}\")\n",
    "\n",
    "nipoppy_redcap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nipoppy_redcap_df[nipoppy_redcap_df[\"participant_id\"]==\"PD01306\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge redcap_report_df with nipoppy_redcap df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nipoppy_redcap_report_df = redcap_report_df[(redcap_report_df[\"participant_id\"].str.upper().isin(nipoppy_participants)) & \n",
    "                              (redcap_report_df[\"redcap_event_name\"].isin(redcap_event_list))].copy()\n",
    "\n",
    "n_nipoppy_redcap_report_participants = len(nipoppy_redcap_report_df[\"participant_id\"].unique())\n",
    "print(f\"n_nipoppy_redcap_participants: {n_nipoppy_redcap_report_participants}\")\n",
    "               \n",
    "nipoppy_redcap_report_df = nipoppy_redcap_report_df.replace(\"\", np.nan)\n",
    "\n",
    "## Get all the age columns\n",
    "nipoppy_redcap_report_df_filtered = nipoppy_redcap_report_df[[\"participant_id\", \"redcap_event_name\", \"group\", \"sex\", \"dob\",\n",
    "                                                               \"moca_date\",\t\"updrs_date\", \"neuropsy_date\", \n",
    "                                                               \"age_moca\", \"age_updrs\", \"age_neuropsy\"]].copy()\n",
    "\n",
    "nipoppy_redcap_filtered_df = pd.merge(nipoppy_redcap_report_df_filtered, nipoppy_redcap_df, \n",
    "                                      on=[\"participant_id\",\"redcap_event_name\"], how=\"left\")\n",
    "\n",
    "n_participants = nipoppy_redcap_filtered_df[\"participant_id\"].nunique()\n",
    "print(f\"n_nipoppy_redcap_report_merged_participants: {n_participants}\")\n",
    "\n",
    "# calculate suivi IRM and dicom ages based on redcap DoB\n",
    "nipoppy_redcap_filtered_df[\"suivi_age_MRI\"] = nipoppy_redcap_filtered_df[\"suivi_MRI_date\"] - nipoppy_redcap_filtered_df[\"dob\"]\n",
    "nipoppy_redcap_filtered_df[\"suivi_age_MRI\"] = np.round(nipoppy_redcap_filtered_df[\"suivi_age_MRI\"].dt.days / 365.25, 2)\n",
    "\n",
    "nipoppy_redcap_filtered_df[\"dicom_age_MRI\"] = nipoppy_redcap_filtered_df[\"scanner_acq_date\"] - nipoppy_redcap_filtered_df[\"dob\"]\n",
    "nipoppy_redcap_filtered_df[\"dicom_age_MRI\"] = np.round(nipoppy_redcap_filtered_df[\"dicom_age_MRI\"].dt.days / 365.25, 2)\n",
    "\n",
    "print(f\"nipoppy_redcap_filtered_df shape: {nipoppy_redcap_filtered_df.shape}\")\n",
    "nipoppy_redcap_filtered_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Sharp Lab's Neurocog dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurocog_data = pd.read_excel(neurocog_date_xlsx, sheet_name=\"Sheet1\", engine='openpyxl')\n",
    "neurocog_data = neurocog_data.rename(columns={\"date_of_assessment\":\"neurocog_date\"})\n",
    "neurocog_data = neurocog_data.drop(columns=[\"assessment\"])\n",
    "neurocog_participants = neurocog_data[\"participant_id\"].unique()\n",
    "n_neurocog_participants = len(neurocog_participants)\n",
    "print(f\"n_neurocog_participants: {n_neurocog_participants} (total rows: {len(neurocog_data)})\")\n",
    "neurocog_screen_participants = set(neurocog_participants) & set(nipoppy_redcap_filtered_df['participant_id'].unique()) \n",
    "neurocog_not_screen_participants = set(neurocog_participants) - set(nipoppy_redcap_filtered_df['participant_id'].unique())\n",
    "screen_not_neurocog_participants = set(nipoppy_redcap_filtered_df['participant_id'].unique()) - set(neurocog_participants)\n",
    "print(f\"neurocog_nipoppy_redcap_filtered_df_participants: {len(neurocog_screen_participants)}\")\n",
    "print(f\"neurocog_not_nipoppy_redcap_filtered_df_participants: {len(neurocog_not_screen_participants)}\")\n",
    "print(f\"nipoppy_redcap_filtered_df_not_neurocog_participants: {len(screen_not_neurocog_participants)}\")\n",
    "\n",
    "neurocog_data[\"REDCap_availability\"] = 1\n",
    "neurocog_data.loc[neurocog_data[\"participant_id\"].isin(neurocog_not_screen_participants), \"REDCap_availability\"] = 0\n",
    "\n",
    "neurocog_data.to_excel(revised_neurocog_date_xlsx, index=False)\n",
    "\n",
    "neurocog_data = neurocog_data.sort_values(by=[\"participant_id\",\"neurocog_date\"])   \n",
    "neurocog_data[neurocog_data.duplicated(subset=[\"participant_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nipoppy_redcap_filtered_df = pd.merge(nipoppy_redcap_filtered_df, neurocog_data, on=[\"participant_id\",\"redcap_event_name\"], how=\"left\")\n",
    "\n",
    "nipoppy_redcap_filtered_df[\"age_neurocog\"] = nipoppy_redcap_filtered_df[\"neurocog_date\"] - nipoppy_redcap_filtered_df[\"dob\"]\n",
    "nipoppy_redcap_filtered_df[\"age_neurocog\"] = np.round(nipoppy_redcap_filtered_df[\"age_neurocog\"].dt.days / 365.25, 2)\n",
    "\n",
    "print(f\"nipoppy_redcap_filtered_df shape: {nipoppy_redcap_filtered_df.shape}\")\n",
    "nipoppy_redcap_filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate bagel(s)\n",
    "- neuro-bagel\n",
    "- dash-bagel (currenly this is a melted version of neuro-bagel)\n",
    "\n",
    "**Note**: QPN has different `visit` names for MRI, UPDRS, MoCA, Neuropsy etc.\n",
    "\n",
    "Using redcap events as evidence of multiple visits. However we are NOT assuming that two assessments (e.g. UPDRS and MoCA) are co-acquired in the same redcap event. This will be inferred using dates once available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redcap_index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "redcap_event_visit_id_dict = {\"Baseline (Arm 1: C-OPN)\": \"v1\"}\n",
    "\n",
    "demo_cols = ['group', 'sex', 'yrs_education']\n",
    "dx_cols = ['diagnosis_determined', 'duration_disease']\n",
    "date_columns = [\"moca_date\", \"updrs_date\", \"neuropsy_date\", \"neurocog_date\", \"suivi_MRI_date\", \"scanner_acq_date\", \"legacy_date_MRI\"]\n",
    "age_cols = [\"legacy_age_MRI\",\"suivi_age_MRI\",\"dicom_age_MRI\",\"age_moca\", \"age_updrs\", \"age_neuropsy\", \"age_neurocog\"]\n",
    "\n",
    "screen_cols = redcap_index_cols + demo_cols + dx_cols + date_columns + age_cols\n",
    "\n",
    "screen_cols_rename_dict = {\n",
    "    \"yrs_education\": \"years_education_at_screening\",\n",
    "    # \"diagnosis_determined\": \"diagnosis\",\n",
    "    \"duration_disease\": \"duration_disease_at_screening\",\n",
    "    \"group\": \"group_at_screening\"\n",
    "}\n",
    "\n",
    "screen_df = nipoppy_redcap_filtered_df[screen_cols].copy()\n",
    "screen_df = screen_df.rename(columns=screen_cols_rename_dict)\n",
    "\n",
    "# ------------------------------------------------------------------------------------ #\n",
    "# Check and add nipoppy participants which yet don't have any redcap data\n",
    "# Only populates the participant_id and bids_id columns (required by neurobagel)\n",
    "# ------------------------------------------------------------------------------------ #\n",
    "nipoppy_participants_without_pheno_data_df = pd.DataFrame()\n",
    "nipoppy_participants_without_pheno_data_df[\"participant_id\"] = list(missing_nipoppy_participants)\n",
    "nipoppy_participants_without_pheno_data_df[\"redcap_event_name\"] = \"missing\"\n",
    "\n",
    "# Add MRI acq dates(only for the first visit because it's tricky to merge without knowing redcap_event_name)\n",
    "MRI_acq_missing_nipoppy_participants_df = MRI_acq_data_df[MRI_acq_data_df[\"session\"]==\"ses-01\"][[\"participant_id\",\"scanner_acq_date\"]].copy()\n",
    "nipoppy_participants_without_pheno_data_df = pd.merge(nipoppy_participants_without_pheno_data_df, MRI_acq_missing_nipoppy_participants_df, on=\"participant_id\", how=\"left\")\n",
    "\n",
    "print(f\"appending {nipoppy_participants_without_pheno_data_df.shape[0]} participants without pheno data\")\n",
    "screen_df = pd.concat([screen_df, nipoppy_participants_without_pheno_data_df], axis=0)\n",
    "\n",
    "print(f\"screen_df participants: {screen_df['participant_id'].nunique()}\")\n",
    "# ------------------------------------------------------------------------------------ #\n",
    "print(f\"screen_df shape: {screen_df.shape}\")\n",
    "screen_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot the screen_df to conform to tabular demographics CSV schema\n",
    "- picking dicom date as the MRI_v1 date. Need to validate these against Suivi dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_assessment_visits(participant_df, id_vars, age_col_dict):\n",
    "\n",
    "    redcap_event_months_dict = {\"Baseline (Arm 1: C-OPN)\": 0, \"12 Months Follow-Up/Suivi (Arm 1: C-OPN)\": 12,\n",
    "                            \"18 Months Follow-Up/Suivi (Arm 1: C-OPN)\": 18, \"24 Months Follow-Up/Suivi (Arm 1: C-OPN)\": 24}\n",
    "\n",
    "    if \"Baseline (Arm 1: C-OPN)\" in participant_df[\"redcap_event_name\"].unique():\n",
    "        participant_df_melt = participant_df.melt(id_vars=id_vars, var_name=\"assessment\", value_name=\"age\")\n",
    "        \n",
    "        # removes assessment rows with missing age (artifact of the melt operation)\n",
    "        participant_df_melt = participant_df_melt.dropna(subset=[\"age\"], how=\"all\", axis=0)\n",
    "\n",
    "        if len(participant_df_melt) > 0:\n",
    "\n",
    "            # assign months_since_baseline to be able to sort the dataframe based on time\n",
    "            participant_df_melt.loc[:,\"months_since_baseline\"] = participant_df_melt[\"redcap_event_name\"].replace(redcap_event_months_dict)\n",
    "            participant_df_melt = participant_df_melt.sort_values([\"participant_id\",\"months_since_baseline\"])\n",
    "            \n",
    "            # drops duplicate MRI visits (artifact of merge operation from MRI dicom dates)\n",
    "            participant_df_melt = participant_df_melt.drop_duplicates(subset=[\"participant_id\",\"assessment\",\"age\"], keep=\"first\")\n",
    "            \n",
    "            participant_df_melt[\"assessment\"] = participant_df_melt[\"assessment\"].replace(age_col_dict)\n",
    "\n",
    "            # \n",
    "            new_participant_df = pd.DataFrame() # avoids messy .loc assignment to the original unsorted df \n",
    "            for assessment in participant_df_melt[\"assessment\"].unique():\n",
    "                participant_assessment_df = participant_df_melt[participant_df_melt[\"assessment\"] == assessment].sort_values(\"age\")\n",
    "                n_visits = len(participant_assessment_df)\n",
    "                # print(f\"n_visits for {assessment}: {n_visits}\")\n",
    "                participant_assessment_df[\"visit_id\"] = np.array(range(1, n_visits+1))\n",
    "                new_participant_df = pd.concat([new_participant_df, participant_assessment_df], axis=0)\n",
    "\n",
    "            new_participant_df = new_participant_df.drop(columns=[\"months_since_baseline\"])   \n",
    "            new_participant_df[\"visit_id\"] = \"v\" + new_participant_df[\"visit_id\"].astype(str)            \n",
    " \n",
    "        else:\n",
    "            print(f\"Participant {participant_df['participant_id'].unique()} has no assessment info\")\n",
    "            new_participant_df = participant_df[id_vars].copy()\n",
    "    else:\n",
    "        print(f\"Participant {participant_df['participant_id'].unique()} has no baseline visit\")\n",
    "        new_participant_df = participant_df[id_vars].copy()\n",
    "\n",
    "    return new_participant_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_vars=[\"participant_id\",\"redcap_event_name\",\"group_at_screening\",\"sex\",\n",
    "         \"years_education_at_screening\",\"duration_disease_at_screening\", \"diagnosis_determined\"]\n",
    "\n",
    "temporal_cols = [\"medication_status\"] + updrs_cols + moca_cols\n",
    "\n",
    "age_col_dict = {\"dicom_age_MRI\": \"MRI\",\n",
    "                \"age_updrs\": \"UPDRS\", \n",
    "                \"age_moca\": \"MOCA\", \n",
    "                \"age_neuropsy\": \"NEUROPSY\",\n",
    "                \"age_neurocog\": \"NEUROCOG\"}\n",
    "\n",
    "demographic_df = pd.DataFrame()\n",
    "for participant_id in screen_df[\"participant_id\"].unique():\n",
    "    participant_df = screen_df[screen_df[\"participant_id\"] == participant_id].copy()\n",
    "    participant_df = participant_df[id_vars + list(age_col_dict.keys())].copy()\n",
    "    participant_df = assign_assessment_visits(participant_df, id_vars, age_col_dict)\n",
    "\n",
    "    if participant_df is not None:\n",
    "        demographic_df = pd.concat([demographic_df, participant_df], axis=0)    \n",
    "\n",
    "\n",
    "demographic_df = demographic_df.sort_values([\"participant_id\", \"visit_id\"])\n",
    "reorder_cols = id_vars + [\"assessment\", \"visit_id\", \"age\"]\n",
    "demographic_df = demographic_df[reorder_cols]\n",
    "\n",
    "demographic_df[\"visit\"] = demographic_df[\"assessment\"] + \"_\" + demographic_df[\"visit_id\"]\n",
    "demographic_df[\"assessment\"] = demographic_df[\"assessment\"].fillna(\"missing\")\n",
    "demographic_df[\"visit_id\"] = demographic_df[\"visit_id\"].fillna(\"v0\")\n",
    "\n",
    "demographic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df[demographic_df[\"participant_id\"] == \"PD01253\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"demographic_df participants: {demographic_df['participant_id'].nunique()}\")\n",
    "print(len(demographic_df))\n",
    "\n",
    "# demographic_df = demographic_df.drop_duplicates(subset=[\"assessment\", \"age\"])\n",
    "\n",
    "print(f\"demographic_df participants: {demographic_df['participant_id'].nunique()}\")\n",
    "print(len(demographic_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df[demographic_df[\"participant_id\"] == \"MNI0342\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Phenotype data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "updrs_df = nipoppy_redcap_filtered_df[redcap_index_cols + updrs_cols].copy()\n",
    "updrs_df[\"assessment\"] = \"UPDRS\"\n",
    "updrs_df[\"medication_status\"] = np.nan\n",
    "\n",
    "moca_df = nipoppy_redcap_filtered_df[redcap_index_cols + moca_cols].copy()\n",
    "moca_df[\"assessment\"] = \"MOCA\"\n",
    "moca_df[\"medication_status\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pheno_id_cols = ['participant_id', 'redcap_event_name','assessment', 'visit_id' ]\n",
    "updrs_df = pd.merge(demographic_df[pheno_id_cols], updrs_df,\n",
    "                    on=['participant_id', 'redcap_event_name', 'assessment'], how=\"right\")\n",
    "moca_df = pd.merge(demographic_df[pheno_id_cols], moca_df,\n",
    "                    on=['participant_id', 'redcap_event_name', 'assessment'], how=\"right\")\n",
    "\n",
    "pheno_df = pd.concat([updrs_df, moca_df], axis=0)\n",
    "\n",
    "pheno_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter NA values from messy merges\n",
    "pheno_df = pheno_df.sort_values([\"participant_id\",\"assessment\", \"visit_id\"])\n",
    "pheno_df = pheno_df.dropna(subset=\"visit_id\", axis=0)\n",
    "pheno_df = pheno_df.drop_duplicates(keep=\"first\")\n",
    "pheno_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df[demographic_df[\"participant_id\"] == \"MNI0206\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_df[pheno_df[\"participant_id\"] == \"MNI0206\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate availability \n",
    "Status options: 1) \"Validated\" 2) \"Missing\" 3) \"Not collected\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagel_df = pd.merge(demographic_df, pheno_df, on=[\"participant_id\",\"redcap_event_name\",\"assessment\",\"visit_id\"], how=\"left\") \n",
    "\n",
    "bagel_participants = bagel_df[\"participant_id\"].unique()\n",
    "print(f\"n_bagel_participants: {len(bagel_participants)}\")\n",
    "\n",
    "bagel_demo_cols = [\"age\", \"sex\", \"years_education_at_screening\", \"duration_disease_at_screening\"]\n",
    "\n",
    "bagel_status_cols = []\n",
    "for col in updrs_cols + moca_cols + bagel_demo_cols:\n",
    "    bagel_df[f\"{col}_status\"] = ~bagel_df[col].isna()\n",
    "    bagel_status_cols.append(f\"{col}_status\")   \n",
    "    if col in bagel_demo_cols:\n",
    "        n_available_participants = np.sum(bagel_df[(bagel_df[\"visit_id\"]==\"v1\") &\n",
    "                                                   (bagel_df[\"assessment\"]==\"MRI\")][f\"{col}_status\"])\n",
    "    else:\n",
    "        n_available_participants = np.sum(bagel_df[(bagel_df[\"visit_id\"]==\"v1\")][f\"{col}_status\"])\n",
    "        \n",
    "    print(f\"{col}, n_available_participants: {n_available_participants}\")\n",
    "\n",
    "print(f\"bagel df shape: {bagel_df.shape}\")\n",
    "\n",
    "bagel_df[\"visit\"] = bagel_df[\"assessment\"] + \"_\" + bagel_df[\"visit_id\"]\n",
    "\n",
    "## Add bids_id\n",
    "participants_with_MRI = bagel_df[bagel_df[\"assessment\"]==\"MRI\"][\"participant_id\"].unique()\n",
    "bagel_df[\"bids_id\"] = \"sub-\" + bagel_df[\"participant_id\"]\n",
    "\n",
    "# bagel_df.loc[~bagel_df[\"participant_id\"].isin(participants_with_MRI), \"bids_id\"] = None  #Neurobagel does not allow bids_id to be None\n",
    "\n",
    "print(\"-\"*50)\n",
    "n_na_participants = bagel_df[\"participant_id\"].isna().sum()\n",
    "n_na_visits = bagel_df[\"visit\"].isna().sum()\n",
    "n_na_bids_id = bagel_df[\"bids_id\"].isna().sum()\n",
    "n_duplicates = bagel_df.duplicated(subset=[\"participant_id\",\"visit\"]).sum()\n",
    "\n",
    "print(f\"n_na_participants: {n_na_participants}\")\n",
    "print(f\"n_na_visits: {n_na_visits}\")\n",
    "print(f\"n_na_bids_id: {n_na_bids_id}\")\n",
    "print(f\"n_duplicates: {n_duplicates}\")\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "bagel_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Status only bagel (no clinical info for public digest/dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagel_id_cols = ['participant_id', 'redcap_event_name', 'group_at_screening', \"diagnosis_determined\", \"assessment\", \"visit_id\"]\n",
    "dash_bagel_df_cols = bagel_id_cols + bagel_status_cols\n",
    "dash_bagel_df = bagel_df[dash_bagel_df_cols].copy()\n",
    "dash_bagel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dash_bagel_df[dash_bagel_df[\"participant_id\"]==\"MNI0056\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dash bagel (melt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard variables\n",
    "DASH_INDEX_COLUMNS = [\"participant_id\", \"redcap_event_name\", \"assessment\", \"visit_id\"]\n",
    "DASH_NAME_COL = \"assessment_name\"\n",
    "DASH_VAL_COL = \"assessment_score\"\n",
    "\n",
    "dash_df = dash_bagel_df.melt(id_vars=DASH_INDEX_COLUMNS, var_name=DASH_NAME_COL, value_name=DASH_VAL_COL)\n",
    "# dash_df = dash_df.rename(columns={\"visit_id\": \"session\"})\n",
    "dash_df[\"session\"] = dash_df[\"assessment\"] + \"_\" + dash_df[\"visit_id\"]\n",
    "\n",
    "# Remove duplicate [`participant_id` x `session`] resulting into NaN assessment score rows\n",
    "dash_df = dash_df.dropna(subset=[\"assessment_score\"], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dash_bagel (with actual data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagel_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard variables\n",
    "DASH_INDEX_COLUMNS = [\"participant_id\", \"redcap_event_name\", \"assessment\", \"visit_id\"]\n",
    "DASH_NAME_COL = \"assessment_name\"\n",
    "DASH_VAL_COL = \"assessment_score\"\n",
    "\n",
    "demo_bagel_df = bagel_df[DASH_INDEX_COLUMNS + [\"years_education_at_screening\", \"duration_disease_at_screening\", \"sex\", \"age\", \"group_at_screening\"]].copy()\n",
    "dash_data_df = demo_bagel_df.melt(id_vars=DASH_INDEX_COLUMNS, var_name=DASH_NAME_COL, value_name=DASH_VAL_COL)\n",
    "# dash_df = dash_df.rename(columns={\"visit_id\": \"session\"})\n",
    "dash_data_df[\"session\"] = dash_data_df[\"assessment\"] + \"_\" + dash_data_df[\"visit_id\"]\n",
    "\n",
    "# Remove duplicate [`participant_id` x `session`] resulting into NaN assessment score rows\n",
    "dash_data_df = dash_data_df.dropna(subset=[\"assessment_score\"], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save phenotypic data\n",
    "- Saves `demographics.csv` --> data collected at screening i.e. age, sex, group, education etc. \n",
    "- Saves `assessments.csv` i.e. collated data from clinical assessments i.e. UPDRS, MoCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pheno = True\n",
    "\n",
    "visits_csv_path = f\"{release_dir}{current_release}/tabular/assessments/visits.csv\"\n",
    "demograph_csv_path = f\"{release_dir}{current_release}/tabular/demographics/demographics.csv\"\n",
    "assessment_csv_path = f\"{release_dir}{current_release}/tabular/assessments/assessments.csv\"\n",
    "\n",
    "print(f\"demographic participants: {demographic_df['participant_id'].nunique()}\")\n",
    "print(f\"pheno participants: {pheno_df['participant_id'].nunique()}\")\n",
    "if save_pheno:\n",
    "    print(f\"Saving data to {demograph_csv_path} and {assessment_csv_path}\")\n",
    "    screen_df.to_csv(visits_csv_path, index=False)\n",
    "    demographic_df.to_csv(demograph_csv_path, index=False)\n",
    "    pheno_df.to_csv(assessment_csv_path, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save bagels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_bagels = True\n",
    "\n",
    "bagel_csv_path = f\"{release_dir}{current_release}/tabular/bagels/bagel.csv\"\n",
    "bagel_tsv_path = f\"{release_dir}{current_release}/tabular/bagels/bagel.tsv\"\n",
    "dash_csv_path = f\"{release_dir}{current_release}/tabular/bagels/dash_bagel.csv\"\n",
    "local_dash_csv_path = f\"{release_dir}{current_release}/tabular/bagels/local_dash_bagel.csv\"\n",
    "public_digest_csv_path = f\"../digest/qpn_tabular_availability_digest.csv\"\n",
    "\n",
    "if save_bagels:\n",
    "    bagel_df.to_csv(bagel_csv_path, index=False)\n",
    "    bagel_df.to_csv(bagel_tsv_path, index=False, sep=\"\\t\")\n",
    "    dash_data_df.to_csv(local_dash_csv_path, index=False)\n",
    "    dash_df.to_csv(dash_csv_path, index=False)\n",
    "    dash_df.to_csv(public_digest_csv_path, index=False)\n",
    "    print(f\"Bagel saved to {dash_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagel_df.groupby([\"visit\"])[\"participant_id\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diff betweeen demo and pheno participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_participants = set(demographic_df['participant_id'].unique())\n",
    "pheno_participants = set(pheno_df['participant_id'].unique())\n",
    "\n",
    "print(f\"demo_participants: {len(demo_participants)}\")\n",
    "print(f\"pheno_participants: {len(pheno_participants)}\")\n",
    "\n",
    "demo_participants_without_pheno_data = list(set(demo_participants).difference(pheno_participants))\n",
    "print(f\"demo_participants_without_pheno_data: {len(demo_participants_without_pheno_data)}\")\n",
    "\n",
    "check_recruit_df = pd.DataFrame(data=demo_participants_without_pheno_data, columns=[\"record_id\"],index=None)\n",
    "check_recruit_df.to_csv(f\"{release_dir}{current_release}/tabular/check_recruit.csv\", index=False)\n",
    "\n",
    "print(f\"Saved {release_dir}{current_release}/tabular/check_recruit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df[demographic_df[\"assessment\"]==\"MRI\"][\"participant_id\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = demographic_df.copy()\n",
    "\n",
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"husl\")\n",
    "    sns.histplot(MRI_age_diff[\"age_diff\"], kde=True, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Longitudinal MRI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_df = demographic_df[demographic_df[\"assessment\"]==\"MRI\"]\n",
    "longitudinal_participants = mri_df[mri_df[\"visit_id\"]==\"v2\"][\"participant_id\"].unique()\n",
    "n_longitudinal_participants = len(longitudinal_participants)\n",
    "print(f\"n_longitudinal_participants: {n_longitudinal_participants}\")\n",
    "longitudinal_mri_df = mri_df[mri_df[\"participant_id\"].isin(longitudinal_participants)]\n",
    "longitudinal_mri_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRI_v1 = longitudinal_mri_df[longitudinal_mri_df[\"visit_id\"]==\"v1\"][[\"participant_id\",\"age\"]].set_index(\"participant_id\")\n",
    "MRI_v2 = longitudinal_mri_df[longitudinal_mri_df[\"visit_id\"]==\"v2\"][[\"participant_id\",\"age\"]].set_index(\"participant_id\")\n",
    "\n",
    "MRI_age_diff = MRI_v2 - MRI_v1\n",
    "MRI_age_diff = MRI_age_diff.rename(columns={\"age\":\"age_diff\"})\n",
    "MRI_age_diff = MRI_age_diff.reset_index()\n",
    "MRI_age_diff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"husl\")\n",
    "    sns.histplot(MRI_age_diff[\"age_diff\"], kde=True, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neurocog ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurocog_df = demographic_df[demographic_df[\"assessment\"]==\"NEUROCOG\"]\n",
    "neurocog_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.plotting_context(\"notebook\", font_scale=1.5):\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.set_palette(\"husl\")\n",
    "    sns.histplot(neurocog_df[\"age\"], kde=True, bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographic_df[demographic_df[\"participant_id\"]==\"PD01306\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_df[screen_df[\"participant_id\"]==\"PD00020\"][date_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dob_df[dob_df[\"participant_id\"]==\"PD01306\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipoppy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
