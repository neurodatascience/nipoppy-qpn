{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "from dateutil import relativedelta\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API call for redcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(url, query, logger=None):\n",
    "    \"\"\" helper function to make API calls to RedCap\n",
    "    \"\"\"\n",
    "    r = requests.post(url, data=query, verify=False)\n",
    "    http_status = str(r.status_code)\n",
    "    print(f'HTTP Status: {http_status}')\n",
    "\n",
    "    if http_status == \"200\":\n",
    "        query_results = r.json()\n",
    "        query_df = pd.DataFrame(query_results)\n",
    "\n",
    "    else:\n",
    "        print(f\"RedCap API request Failed with HTTP Status: {http_status}\")\n",
    "        query_df = None\n",
    "        \n",
    "    return query_df\n",
    "\n",
    "def get_inventory_count(df, index_col, availability_indicators):\n",
    "    \"\"\" helper function to count participants with recorded data in redcap\n",
    "    \"\"\"\n",
    "    assess_cols = df.columns.drop(index_col)\n",
    "\n",
    "    if availability_indicators == 'number':\n",
    "        df = df.replace(\"\", np.nan)\n",
    "        df[assess_cols] = df[assess_cols].astype(np.float64)\n",
    "\n",
    "    inventory = {}\n",
    "    for col in assess_cols:        \n",
    "        if availability_indicators == 'number':\n",
    "            availability_count = df[~df[col].isna()][index_col].nunique()\n",
    "        else:\n",
    "            availability_count = df[df[col].isin(availability_indicators)][index_col].nunique()\n",
    "        inventory[col] = availability_count\n",
    "    return inventory\n",
    "\n",
    "def get_available_data(config_json, DATASET_ROOT, var_name, preferred_var_source=\"primary\"):\n",
    "    \"\"\" Get data for given variables from available sources\n",
    "        All return dataframes should have participant_id and visit_id as index\n",
    "    \"\"\"\n",
    "    config_data = json.load(open(config_json))\n",
    "    data_sources = config_data['data_sources']\n",
    "    variable_info = config_data['variables'][var_name]\n",
    "    variable_type = variable_info[\"type\"]\n",
    "    variable_sources = variable_info[\"sources\"]\n",
    "\n",
    "    if preferred_var_source == \"primary\":\n",
    "        selected_var_source = variable_info['primary_source']\n",
    "        selected_var_instrument = variable_info['primary_instrument']\n",
    "    elif preferred_var_source == \"secondary\":\n",
    "        selected_var_source = variable_info['secondary_source']\n",
    "        selected_var_instrument = variable_info['secondary_instrument']\n",
    "    else:\n",
    "        print(f\"Using preferred source {preferred_var_source} for variable {var_name}\")\n",
    "        preferred_var_data_source = preferred_var_source[\"data_source\"]\n",
    "        preferred_var_instrument = preferred_var_source[\"instrument\"]\n",
    "\n",
    "        if preferred_var_data_source not in variable_sources.keys():\n",
    "            print(f\"Preferred data source {preferred_var_data_source} not available for variable {var_name}\")\n",
    "            return None\n",
    "        else:\n",
    "            selected_var_source = preferred_var_data_source\n",
    "\n",
    "        if preferred_var_instrument not in variable_sources[selected_var_source].keys():\n",
    "            print(f\"Preferred var instrument {preferred_var_instrument} not available for variable {var_name}\")\n",
    "            return None\n",
    "        else:\n",
    "            selected_var_instrument = preferred_var_instrument\n",
    "\n",
    "    print(f\"Using variable {var_name} from source {selected_var_source} and instrument {selected_var_instrument}\")\n",
    "\n",
    "    external_var_cols = variable_sources[selected_var_source][selected_var_instrument]\n",
    "\n",
    "    # Get data from primary source\n",
    "    var_file = data_sources[selected_var_source][selected_var_instrument][\"path\"]\n",
    "    var_file_path = f\"{DATASET_ROOT}/{var_file}\"\n",
    "    var_file_index = data_sources[selected_var_source][selected_var_instrument][\"index_cols\"]\n",
    "\n",
    "    var_df = pd.read_csv(var_file_path)\n",
    "    selected_var_cols = list(set(var_file_index + external_var_cols))\n",
    "    var_df = var_df[selected_var_cols]\n",
    "    \n",
    "    if (variable_type == \"date\") & (len(external_var_cols) == 1):\n",
    "        var_df[external_var_cols[0]] = pd.to_datetime(var_df[external_var_cols[0]], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "    if (len(external_var_cols) == 1):\n",
    "        var_df = var_df.rename(columns={external_var_cols[0]:var_name})\n",
    "    \n",
    "    return var_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/nikhil/projects/Parkinsons/qpn/\"\n",
    "\n",
    "# Current nipoppy manifest\n",
    "release_dir = f\"{DATASET_ROOT}/releases/\"\n",
    "current_release = \"Jan_2024\"\n",
    "\n",
    "tabular_data_release_dir = f\"{release_dir}/{current_release}/\"\n",
    "\n",
    "demo_config_json = \"../workflow/tabular/demographics.json\"\n",
    "pheno_config_json = \"../workflow/tabular/pheno.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_event_name = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "## redcap event name variations\n",
    "config_data = json.load(open(demo_config_json))\n",
    "data_sources = config_data['data_sources']\n",
    "redcap_data_sources = data_sources['redcap']\n",
    "\n",
    "redcap_field_name_map = {}\n",
    "\n",
    "for instrument in redcap_data_sources.keys():\n",
    "    index_cols = redcap_data_sources[instrument]['index_cols']\n",
    "    record_id = index_cols[0]\n",
    "    event_name = index_cols[1]\n",
    "\n",
    "    redcap_field_name_map[record_id] = \"participant_id\"\n",
    "    redcap_field_name_map[event_name] = \"redcap_event_name\"\n",
    "\n",
    "# legacy participant_id variations in DOB\n",
    "redcap_field_name_map['Record ID'] = \"participant_id\"\n",
    "redcap_field_name_map\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update RedCAP reports through API \n",
    "(Not updating extended report since it has to come from Sarah)\n",
    "- \"global_records_query\"\n",
    "- \"QPN MoCA-UPDRS-Neuropsy data_Sarah\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_redcap_reports = False\n",
    "\n",
    "redcap_report_list = [\"global_records_query\", \"QPN MoCA-UPDRS-Neuropsy data_Sarah\"]\n",
    "if update_redcap_reports:\n",
    "    redcap_config_json = f\"{DATASET_ROOT}/proc/.redcap.json\"\n",
    "    redcap_config = json.load(open(redcap_config_json))\n",
    "    url = redcap_config[\"url\"]\n",
    "    \n",
    "    for redcap_report in redcap_report_list:\n",
    "        print(f\"Getting data for RedCap report: {redcap_report}\")\n",
    "        records_query = redcap_config[\"queries\"][redcap_report]\n",
    "        query_df = api_call(url, records_query, logger=None)\n",
    "        report_csv = f\"{release_dir}{current_release}/tabular/redcap/{redcap_report}.csv\"\n",
    "        query_df.to_csv(report_csv, index=False)\n",
    "        print(f\"Saved RedCap report to {report_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QPN_participants_df = get_available_data(demo_config_json,tabular_data_release_dir,\"participant_id\")\n",
    "QPN_participants = QPN_participants_df[\"participant_id\"].unique()\n",
    "n_participants = len(QPN_participants)\n",
    "print(f\"Number of participants: {n_participants}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_vars = [\"dob\", \"group\", \"sex\"]\n",
    "# preferred_var_source = {\"data_source\":\"local\",\"instrument\":\"legacy_DOB\"}\n",
    "vars_with_secondary_source = [\"dob\"]\n",
    "\n",
    "config_json = demo_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "\n",
    "demo_var_df = pd.DataFrame()\n",
    "for var in demo_vars:\n",
    "    _df = get_available_data(config_json,tabular_data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "\n",
    "    if var in vars_with_secondary_source:\n",
    "        print(f\"**Getting data from the secondary source for variable {var}**\")\n",
    "        _df2 = get_available_data(config_json,tabular_data_release_dir,var,preferred_var_source=\"secondary\")\n",
    "        _df2 = _df2.rename(columns=redcap_field_name_map)\n",
    "        _df2 = _df2.rename(columns={var:var+\"_secondary\"})\n",
    "        _df2 = _df2[_df2[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "        \n",
    "        # Merge primary and secondary sources\n",
    "        n_missing_in_primary = _df[_df[\"redcap_event_name\"]==baseline_event_name][var].isna().sum()\n",
    "        print(f\"Missing data in primary source: {n_missing_in_primary}\")\n",
    "\n",
    "        if \"redcap_event_name\" in _df2.columns:\n",
    "            _df = pd.merge(_df, _df2, on=[\"participant_id\",\"redcap_event_name\"], how=\"outer\")\n",
    "        else:\n",
    "            _df = pd.merge(_df, _df2, on=\"participant_id\", how=\"outer\")\n",
    "        _df[var] = _df[var].fillna(_df[var+\"_secondary\"])\n",
    "        # _df = _df.drop(columns=[var+\"_secondary\"])\n",
    "\n",
    "        n_missing_after_secondary_fill = _df[_df[\"redcap_event_name\"]==baseline_event_name][var].isna().sum()\n",
    "        print(f\"Missing data after secondary source fill: {n_missing_after_secondary_fill}\")\n",
    "\n",
    "    if demo_var_df.empty:\n",
    "        demo_var_df = _df\n",
    "    else:\n",
    "        demo_var_df = pd.merge(demo_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "demo_participants = demo_var_df[\"participant_id\"].unique()\n",
    "n_demo_participants = len(demo_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with demographics data: {n_demo_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "demo_redcap_events = demo_var_df[\"redcap_event_name\"].unique()\n",
    "print(f\"Demographics data available for events: {demo_redcap_events}\")\n",
    "print('-'*50)\n",
    "\n",
    "for var in demo_vars:\n",
    "    n_unique = demo_var_df[demo_var_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"][var].nunique()\n",
    "    n_missing = demo_var_df[demo_var_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"][var].isna().sum()\n",
    "    print(f\"Var: {var}, n_unique: {n_unique}, n_missing: {n_missing} (out of {n_demo_participants})\")\n",
    "\n",
    "demo_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find records with phenotypic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_vars = [\"diagnosis\", \"updrs_score\", \"moca_score\", \"diagnosis_date\", \"updrs_date\", \"moca_date\"]\n",
    "# preferred_var_source = {\"data_source\":\"local\",\"instrument\":\"legacy_DOB\"}\n",
    "\n",
    "config_json = pheno_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "pheno_var_df = pd.DataFrame()\n",
    "for var in pheno_vars:\n",
    "    _df = get_available_data(config_json,tabular_data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "    if pheno_var_df.empty:\n",
    "        pheno_var_df = _df\n",
    "    else:\n",
    "        pheno_var_df = pd.merge(pheno_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "pheno_participants = pheno_var_df[\"participant_id\"].unique()\n",
    "n_pheno_participants = len(pheno_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with pheno data: {n_pheno_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "pheno_redcap_events = pheno_var_df[\"redcap_event_name\"].unique()\n",
    "print(f\"Pheno data available for events: {pheno_redcap_events}\")\n",
    "print('-'*50)\n",
    "\n",
    "for var in pheno_var_df.columns:\n",
    "    for redcap_event in pheno_redcap_events:\n",
    "        if var not in index_cols:\n",
    "            pheno_var_event_df = pheno_var_df[pheno_var_df[\"redcap_event_name\"]==redcap_event].copy()\n",
    "            n_pheno_var_event_participants = pheno_var_event_df[\"participant_id\"].nunique()\n",
    "            if pheno_var_event_df[var].nunique() > 0:    \n",
    "                print(f\"Var: {var}, Event: {redcap_event}\")\n",
    "                n_unique = pheno_var_event_df[var].nunique()\n",
    "                n_missing = pheno_var_event_df[var].isna().sum()\n",
    "                print(f\"n_unique: {n_unique}, n_missing: {n_missing} (out of {n_pheno_var_event_participants})\")\n",
    "    print('-'*50)\n",
    "\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add mri_acq date\n",
    "- Needs to map to redcap_event_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"MRI_date\"\n",
    "config_json = pheno_config_json\n",
    "mri_date_df = get_available_data(config_json,tabular_data_release_dir,var)\n",
    "mri_date_df[\"MRI_date\"] = pd.to_datetime(mri_date_df[\"MRI_date\"], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "n_mri_participants = mri_date_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants with MRI data: {n_mri_participants}\")\n",
    "\n",
    "n_sessions = mri_date_df[\"session\"].nunique()\n",
    "print(f\"Number of MRI sessions: {n_sessions}\")\n",
    "\n",
    "participants_with_follow_ups = mri_date_df[mri_date_df[\"participant_id\"].duplicated()][\"participant_id\"].unique()\n",
    "n_participants_with_follow_ups = len(participants_with_follow_ups)\n",
    "print(f\"Number of participants with follow-up MRI: {n_participants_with_follow_ups}\")\n",
    "\n",
    "mri_ses01_date_df = mri_date_df[mri_date_df[\"session\"]==\"ses-01\"].copy()\n",
    "mri_ses01_date_df[\"redcap_event_name\"] = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "mri_ses02_date_df = mri_date_df[mri_date_df[\"session\"]==\"ses-02\"].copy()\n",
    "mri_ses02_participants = mri_ses02_date_df[\"participant_id\"].unique()\n",
    "print(f\"Number of participants with ses-02 MRI: {len(mri_ses02_participants)}\")\n",
    "\n",
    "baseline_df = mri_ses01_date_df[mri_ses01_date_df[\"participant_id\"].isin(mri_ses02_participants)].set_index(\"participant_id\")\n",
    "followup_df = mri_ses02_date_df.set_index(\"participant_id\")\n",
    "\n",
    "# --- Bin the months --- #\n",
    "followup_df[\"months_since_baseline\"] = followup_df[\"MRI_date\"].dt.to_period('M').astype(int) - baseline_df[\"MRI_date\"].dt.to_period('M').astype(int)\n",
    "followup_df.loc[(followup_df[\"months_since_baseline\"] > 9) & \n",
    "         (followup_df[\"months_since_baseline\"] <= 15), \"redcap_event_name\"] = \"12 Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "followup_df.loc[(followup_df[\"months_since_baseline\"] > 15) &\n",
    "         (followup_df[\"months_since_baseline\"] <= 21), \"redcap_event_name\"] = \"18 Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "followup_df.loc[(followup_df[\"months_since_baseline\"] > 21) &\n",
    "         (followup_df[\"months_since_baseline\"] <= 27), \"redcap_event_name\"] = \"24 Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "followup_df.loc[(followup_df[\"months_since_baseline\"] > 27) &\n",
    "        (followup_df[\"months_since_baseline\"] <= 33), \"redcap_event_name\"] = \"30 Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "followup_df.loc[(followup_df[\"months_since_baseline\"] > 33) &\n",
    "         (followup_df[\"months_since_baseline\"] <= 39), \"redcap_event_name\"] = \"36 Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "followup_df.loc[(followup_df[\"months_since_baseline\"] > 39) &\n",
    "         (followup_df[\"months_since_baseline\"] <= 45), \"redcap_event_name\"] = \"42 Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "followup_df.loc[(followup_df[\"months_since_baseline\"] > 45) &\n",
    "         (followup_df[\"months_since_baseline\"] <= 51), \"redcap_event_name\"] = \"48 Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "followup_df.loc[(followup_df[\"months_since_baseline\"] > 51) &\n",
    "         (followup_df[\"months_since_baseline\"] <= 57), \"redcap_event_name\"] = \"54 Months Follow-Up/Suivi (Arm 1: C-OPN)\"            \n",
    "\n",
    "# --- Bin the months --- #\n",
    "\n",
    "mri_date_redcap_event_df = pd.concat([mri_ses01_date_df, followup_df.reset_index()], axis=0)\n",
    "# mri_date_redcap_event_df = mri_date_redcap_event_df\n",
    "\n",
    "mri_date_redcap_event_df.sort_values([\"participant_id\",\"session\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add MRI date to pheno data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_var_df = pd.merge(pheno_var_df, mri_date_redcap_event_df, on=index_cols, how=\"right\")  \n",
    "var = \"MRI_date\"\n",
    "for redcap_event in mri_date_redcap_event_df[\"redcap_event_name\"].unique():    \n",
    "    pheno_var_event_df = pheno_var_df[pheno_var_df[\"redcap_event_name\"]==redcap_event].copy()\n",
    "    n_pheno_var_event_participants = pheno_var_event_df[\"participant_id\"].nunique()\n",
    "    if pheno_var_event_df[var].nunique() > 0:    \n",
    "        print(f\"Var: {var}, Event: {redcap_event}\")\n",
    "        n_unique = pheno_var_event_df[var].nunique()\n",
    "        n_missing = pheno_var_event_df[var].isna().sum()\n",
    "        print(f\"n_unique: {n_unique}, n_missing: {n_missing} (out of {n_pheno_var_event_participants})\")\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipoppy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
