{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "from dateutil import relativedelta\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API call for redcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(url, query, logger=None):\n",
    "    \"\"\" helper function to make API calls to RedCap\n",
    "    \"\"\"\n",
    "    r = requests.post(url, data=query, verify=False)\n",
    "    http_status = str(r.status_code)\n",
    "    print(f'HTTP Status: {http_status}')\n",
    "\n",
    "    if http_status == \"200\":\n",
    "        query_results = r.json()\n",
    "        query_df = pd.DataFrame(query_results)\n",
    "\n",
    "    else:\n",
    "        print(f\"RedCap API request Failed with HTTP Status: {http_status}\")\n",
    "        query_df = None\n",
    "        \n",
    "    return query_df\n",
    "\n",
    "def get_inventory_count(df, index_col, availability_indicators):\n",
    "    \"\"\" helper function to count participants with recorded data in redcap\n",
    "    \"\"\"\n",
    "    assess_cols = df.columns.drop(index_col)\n",
    "\n",
    "    if availability_indicators == 'number':\n",
    "        df = df.replace(\"\", np.nan)\n",
    "        df[assess_cols] = df[assess_cols].astype(np.float64)\n",
    "\n",
    "    inventory = {}\n",
    "    for col in assess_cols:        \n",
    "        if availability_indicators == 'number':\n",
    "            availability_count = df[~df[col].isna()][index_col].nunique()\n",
    "        else:\n",
    "            availability_count = df[df[col].isin(availability_indicators)][index_col].nunique()\n",
    "        inventory[col] = availability_count\n",
    "    return inventory\n",
    "\n",
    "def get_available_data(config_json, DATASET_ROOT, var_name, preferred_var_source=\"primary\"):\n",
    "    \"\"\" Get data for given variables from available sources\n",
    "        All return dataframes should have participant_id and visit_id as index\n",
    "    \"\"\"\n",
    "    config_data = json.load(open(config_json))\n",
    "    data_sources = config_data['data_sources']\n",
    "    variable_info = config_data['variables'][var_name]\n",
    "    variable_type = variable_info[\"type\"]\n",
    "    variable_sources = variable_info[\"sources\"]\n",
    "\n",
    "    if preferred_var_source == \"primary\":\n",
    "        selected_var_source = variable_info['primary_source']\n",
    "        selected_var_instrument = variable_info['primary_instrument']\n",
    "    elif preferred_var_source == \"secondary\":\n",
    "        selected_var_source = variable_info['secondary_source']\n",
    "        selected_var_instrument = variable_info['secondary_instrument']\n",
    "    else:\n",
    "        print(f\"Using preferred source {preferred_var_source} for variable {var_name}\")\n",
    "        preferred_var_data_source = preferred_var_source[\"data_source\"]\n",
    "        preferred_var_instrument = preferred_var_source[\"instrument\"]\n",
    "\n",
    "        if preferred_var_data_source not in variable_sources.keys():\n",
    "            print(f\"Preferred data source {preferred_var_data_source} not available for variable {var_name}\")\n",
    "            return None\n",
    "        else:\n",
    "            selected_var_source = preferred_var_data_source\n",
    "\n",
    "        if preferred_var_instrument not in variable_sources[selected_var_source].keys():\n",
    "            print(f\"Preferred var instrument {preferred_var_instrument} not available for variable {var_name}\")\n",
    "            return None\n",
    "        else:\n",
    "            selected_var_instrument = preferred_var_instrument\n",
    "\n",
    "    print(f\"Using variable {var_name} from source {selected_var_source} and instrument {selected_var_instrument}\")\n",
    "\n",
    "    external_var_cols = variable_sources[selected_var_source][selected_var_instrument]\n",
    "\n",
    "    # Get data from primary source\n",
    "    var_file = data_sources[selected_var_source][selected_var_instrument][\"path\"]\n",
    "    var_file_path = f\"{DATASET_ROOT}/{var_file}\"\n",
    "    var_file_index = data_sources[selected_var_source][selected_var_instrument][\"index_cols\"]\n",
    "\n",
    "    var_df = pd.read_csv(var_file_path)\n",
    "    selected_var_cols = list(set(var_file_index + external_var_cols))\n",
    "    var_df = var_df[selected_var_cols]\n",
    "    \n",
    "    if (variable_type == \"date\") & (len(external_var_cols) == 1):\n",
    "        var_df[external_var_cols[0]] = pd.to_datetime(var_df[external_var_cols[0]], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "    if (len(external_var_cols) == 1):\n",
    "        var_df = var_df.rename(columns={external_var_cols[0]:var_name})\n",
    "    \n",
    "    return var_df\n",
    "\n",
    "def get_age_at_visit(df, date_col, age_col, dob_col=\"dob\", rounding_digits=2, age_range=(0,100)):\n",
    "    \"\"\" Get age at visit. Expects column name to be: var_date \"\"\"\n",
    "    \n",
    "    df[age_col] = df[date_col] - df[dob_col]\n",
    "    df[age_col] = np.round(df[age_col].dt.days / 365.25, rounding_digits)\n",
    "\n",
    "    if (len(df[df[age_col] > 100]) | len(df[df[age_col] < 0])):\n",
    "        print(f\"Warning: Age values outside range {age_range} for variable {var}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/nikhil/projects/Parkinsons/qpn/\"\n",
    "\n",
    "# Current nipoppy release\n",
    "current_release = \"Oct_2024\"\n",
    "\n",
    "data_release_dir = f\"{DATASET_ROOT}/releases/{current_release}/\"\n",
    "tabular_data_release_dir = f\"{data_release_dir}/tabular/\"\n",
    "\n",
    "redcap_release_dir = f\"{data_release_dir}tabular/redcap/chunked/\"\n",
    "# redcap_chunked_report_COPY = f\"{redcap_release_dir}/1. COPN-QPNDataMoCAUPDRSNeur_DATA_LABELS_2024-06-19_0910_copy.xlsx\"\n",
    "# colleted_redcap_report_file = f\"{redcap_release_dir}/redcap_chunked_report.csv\"\n",
    "\n",
    "redcap_legacy_updrs_file = f\"{redcap_release_dir}/COPN-QPNMDSUPDRS_DATA_LABELS_2024-06-19_0945.xlsx\"\n",
    "redcap_legacy_moca_file = f\"{redcap_release_dir}/COPN-QPNMoCA_DATA_LABELS_2024-06-19_0938.xlsx\"\n",
    "\n",
    "filtered_legacy_updrs_file = f\"{redcap_release_dir}/legacy_updrs.csv\"\n",
    "collated_moca_file = f\"{redcap_release_dir}/redcap_and_legacy_moca.csv\"\n",
    "\n",
    "demo_config_json = \"../workflow/tabular/demographics.json\"\n",
    "pheno_config_json = \"../workflow/tabular/pheno.json\"\n",
    "\n",
    "# Special cohort inclusion/exclusion criteria files\n",
    "# These files are used to filter participants based on certain criteria - typically would go inside `demographics.csv` \n",
    "## Roche participant list\n",
    "roche_participant_list_csv = f\"{tabular_data_release_dir}/recruitment/roche_participants.csv\"\n",
    "retracted_participant_list_csv = f\"{tabular_data_release_dir}/recruitment/retracted_participants.csv\"\n",
    "\n",
    "# Neuromelanin cohort\n",
    "neuromelanin_participant_list_csv = f\"{tabular_data_release_dir}/recruitment/MRI_NM_LORIS_map.csv\"\n",
    "\n",
    "# output files\n",
    "demographics_file = f\"{tabular_data_release_dir}/demographics.csv\"\n",
    "mri_session_date_file = f\"{tabular_data_release_dir}/mri_info/mri_sessions.csv\"\n",
    "updrs_file = f\"{tabular_data_release_dir}/assessments/updrs.csv\"\n",
    "moca_file = f\"{tabular_data_release_dir}/assessments/moca.csv\"\n",
    "dx_file = f\"{tabular_data_release_dir}/assessments/diagnosis.csv\"\n",
    "neuropsych_file = f\"{tabular_data_release_dir}/assessments/neuropsych.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_event_name = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "## redcap event name variations\n",
    "config_data = json.load(open(demo_config_json))\n",
    "data_sources = config_data['data_sources']\n",
    "redcap_data_sources = data_sources['redcap']\n",
    "\n",
    "redcap_field_name_map = {}\n",
    "\n",
    "for instrument in redcap_data_sources.keys():\n",
    "    index_cols = redcap_data_sources[instrument]['index_cols']\n",
    "    record_id = index_cols[0]\n",
    "    event_name = index_cols[1]\n",
    "\n",
    "    redcap_field_name_map[record_id] = \"participant_id\"\n",
    "    redcap_field_name_map[event_name] = \"redcap_event_name\"\n",
    "print(f\"redcap_field_name_map: {redcap_field_name_map}\")\n",
    "\n",
    "# legacy participant_id variations in DOB and BD_RPQ\n",
    "legacy_field_name_map = {}\n",
    "legacy_field_name_map['Record ID'] = \"participant_id\"\n",
    "legacy_field_name_map['Patient #'] = \"participant_id\"\n",
    "legacy_field_name_map['Name of visit (V01, V02, V03)'] = \"visit\"\n",
    "print(f\"legacy_field_name_map: {legacy_field_name_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update RedCAP reports through API \n",
    "(Not updating extended report since it has to come from Sarah)\n",
    "- \"global_records_query\"\n",
    "- \"QPN MoCA-UPDRS-Neuropsy data_Sarah\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_redcap_reports = False\n",
    "\n",
    "redcap_report_list = [\"MDSUPDRS-1_Base\"] #[\"Demographic QPN\", \"global_records_query\", \"QPN MoCA-UPDRS-Neuropsy data_Sarah\"]\n",
    "if update_redcap_reports:\n",
    "    redcap_config_json = f\"{DATASET_ROOT}/proc/.redcap.json\"\n",
    "    redcap_config = json.load(open(redcap_config_json))\n",
    "    url = redcap_config[\"url\"]\n",
    "    \n",
    "    for redcap_report in redcap_report_list:\n",
    "        print(f\"Getting data for RedCap report: {redcap_report}\")\n",
    "        records_query = redcap_config[\"queries\"][redcap_report]\n",
    "        query_df = api_call(url, records_query, logger=None)\n",
    "        report_csv = f\"{tabular_data_release_dir}/redcap/{redcap_report}.csv\"\n",
    "        query_df.to_csv(report_csv, index=False)\n",
    "        print(f\"Saved RedCap report to {report_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QPN_participants_df = get_available_data(demo_config_json,data_release_dir,\"participant_id\")\n",
    "QPN_participants = QPN_participants_df[\"participant_id\"].unique()\n",
    "n_participants = len(QPN_participants)\n",
    "session_counts = QPN_participants_df[\"participant_id\"].value_counts()\n",
    "print(f\"Number of participants: {n_participants}\")\n",
    "\n",
    "### Retracted participants\n",
    "print(f\"Removing retracted participants from the dataset\")\n",
    "retracted_participants_df = pd.read_csv(retracted_participant_list_csv)\n",
    "retracted_participants = retracted_participants_df[\"participant_id\"].unique()\n",
    "print(f\"removing following {len(retracted_participants)} participants from the dataset: {retracted_participants}\")\n",
    "QPN_participants_df = QPN_participants_df[~QPN_participants_df[\"participant_id\"].isin(retracted_participants)].copy()\n",
    "\n",
    "QPN_participants = QPN_participants_df[\"participant_id\"].unique()\n",
    "n_participants = len(QPN_participants)\n",
    "session_counts = QPN_participants_df[\"participant_id\"].value_counts()\n",
    "print(f\"Number of participants: {n_participants}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate chunked RedCap data\n",
    "- The new generate report is formatted as mutli-tab excel spreadsheet based on redcap-event. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_collated_report = False\n",
    "\n",
    "if regenerate_collated_report:\n",
    "    sheet_names = [\"Baseline (without CHQ)\",\"F-U 12months & MNI\",\"F-U 18months & MNI\", \"F-U 24months & MNI\",\n",
    "                \"F-U 12months & PD, UDM\", \"F-U 18months & PD, UDM\", \"F-U 24months & PD, UDM\"]\n",
    "    redcap_chunked_report_df = pd.DataFrame()\n",
    "    for sheet_name in sheet_names:\n",
    "        _df = pd.read_excel(redcap_chunked_report_COPY, sheet_name=sheet_name, engine='openpyxl')\n",
    "        _df = _df[_df[\"Record ID:\"].isin(QPN_participants)]  \n",
    "        redcap_chunked_report_df = pd.concat([redcap_chunked_report_df, _df], axis=0)\n",
    "        print(f\"Sheet: {sheet_name} - Shape: {_df.shape}\")\n",
    "        print(f\"redcap_chunked_report_df - Shape: {redcap_chunked_report_df.shape}\")\n",
    "\n",
    "    print(f\"Saving collated redcap report to {redcap_release_dir}/redcap_chunked_report.csv\")\n",
    "    redcap_chunked_report_df.to_csv(collated_redcap_report_file, index=False)\n",
    "\n",
    "else:\n",
    "    print(f\"Loading collated redcap report from {redcap_release_dir}/redcap_chunked_report.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate and calculate legacy UPDRS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_legacy_data = False\n",
    "\n",
    "if regenerate_legacy_data:\n",
    "    legacy_updrs_df = pd.read_excel(redcap_legacy_updrs_file, engine='openpyxl')\n",
    "\n",
    "    all_updrs3_cols = legacy_updrs_df.columns[legacy_updrs_df.columns.str.startswith(\"Updrs_3\")]\n",
    "    all_legacy_cols = legacy_updrs_df.columns[legacy_updrs_df.columns.str.endswith(\".1\")]\n",
    "\n",
    "    legacy_updrs3_cols = list(set(all_updrs3_cols) & set(all_legacy_cols))\n",
    "\n",
    "    legacy_total_cols = ['Part I: Non-Motor Aspects of Experiences of Daily Living (nM-EDL).1',\n",
    "                        'Part II: Motor Aspects of Experiences of Daily Living (M-EDL).1',\t\n",
    "                        'Part III: Motor Examination.1',\n",
    "                        'Part IV: Motor Complications.1']\n",
    "\n",
    "    legacy_admin_cols = ['Record ID:',\t'Event Name',\n",
    "                        'Assessment completed:     Évaluation remplie:  .1',\n",
    "                        'Assessment completed by:     Évaluation complétée par:.1',\n",
    "                        'How was the MDS-UPDRS administered?   Comment le MDS-UPDRS a-t-il été administré?.1']\n",
    "\n",
    "\n",
    "    legacy_filter_cols = legacy_admin_cols + legacy_total_cols + legacy_updrs3_cols\n",
    "\n",
    "    legacy_updrs_filtered_df = legacy_updrs_df.loc[:, legacy_filter_cols]\n",
    "\n",
    "    legacy_updrs_filtered_df = legacy_updrs_filtered_df.dropna(subset=legacy_updrs3_cols, how='all')\n",
    "\n",
    "    # Filter out two subjects that have all UPDRS subscore (most likely not legacy instrument)\n",
    "    legacy_updrs_filtered_df = legacy_updrs_filtered_df[legacy_updrs_filtered_df[\"Updrs_3_16_l value.1\"].isna()]\n",
    "\n",
    "    n_legacy_participants = legacy_updrs_filtered_df[\"Record ID:\"].nunique()\n",
    "\n",
    "    print(f\"Number of participants with legacy UPDRS data: {n_legacy_participants}\")\n",
    "\n",
    "    print(\"Summing all UPDRS3 sub-scores\")\n",
    "    legacy_updrs_filtered_df[\"legacy_updrs3\"] = legacy_updrs_filtered_df[legacy_updrs3_cols].sum(axis=1)\n",
    "    legacy_updrs_filtered_df[\"Event Name\"] = \"pre-redcap-baseline-1 (legacy)\"\n",
    "\n",
    "    print(f\"Saving filtered legacy UPDRS data to {filtered_legacy_updrs_file}\")\n",
    "    legacy_updrs_filtered_df.to_csv(filtered_legacy_updrs_file, index=False)\n",
    "\n",
    "    legacy_updrs_filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collate and calculate legacy MoCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "regenerate_legacy_data = False\n",
    "\n",
    "if regenerate_legacy_data:\n",
    "    moca_df = pd.read_excel(redcap_legacy_moca_file, engine='openpyxl')\n",
    "\n",
    "    first_legacy_cols = moca_df.columns[moca_df.columns.str.endswith(\".1\")]\n",
    "    second_legacy_cols = moca_df.columns[moca_df.columns.str.endswith(\".2\")]\n",
    "\n",
    "    index_cols = ['Record ID:',\t'Event Name']\n",
    "    first_legacy_moca_df = moca_df.loc[:, index_cols + list(first_legacy_cols)]\n",
    "    second_legacy_moca_df = moca_df.loc[:, index_cols + list(second_legacy_cols)]\n",
    "\n",
    "    n_first_legacy_participants = first_legacy_moca_df[\"Record ID:\"].nunique()\n",
    "    n_second_legacy_participants = second_legacy_moca_df[\"Record ID:\"].nunique()\n",
    "\n",
    "    print(f\"Number of participants with first legacy MoCA data: {n_first_legacy_participants}\")\n",
    "    print(f\"Number of participants with second legacy MoCA data: {n_second_legacy_participants}\")\n",
    "\n",
    "    # merge first and second legacy moca data\n",
    "    moca_cols = first_legacy_cols.str.replace(\".1\",\"\")\n",
    "    first_legacy_cols_dict = dict(zip(first_legacy_cols, moca_cols))\n",
    "    second_legacy_cols_dict = dict(zip(second_legacy_cols, moca_cols))\n",
    "\n",
    "    first_legacy_moca_df = first_legacy_moca_df.rename(columns=first_legacy_cols_dict)\n",
    "    first_legacy_moca_df[\"Event Name\"] = \"pre-redcap-baseline-1 (legacy)\"\n",
    "\n",
    "    second_legacy_moca_df = second_legacy_moca_df.rename(columns=second_legacy_cols_dict)\n",
    "    second_legacy_moca_df[\"Event Name\"] = \"pre-redcap-baseline-2 (legacy)\"\n",
    "\n",
    "    legacy_moca_df = pd.concat([first_legacy_moca_df, second_legacy_moca_df], axis=0)\n",
    "\n",
    "    na_check_cols = legacy_moca_df.columns[legacy_moca_df.columns.str.startswith(\"TOTAL\")]\n",
    "\n",
    "    legacy_moca_df = legacy_moca_df.dropna(subset=na_check_cols, how='all')\n",
    "\n",
    "    n_legacy_participants = legacy_moca_df[\"Record ID:\"].nunique()\n",
    "    legacy_visit_counts = legacy_moca_df[\"Event Name\"].value_counts()\n",
    "\n",
    "    print(f\"Number of participants with legacy MoCA data: {n_legacy_participants}\")\n",
    "    print(f\"legacy_visit_counts MoCA data: {legacy_visit_counts}\")\n",
    "\n",
    "\n",
    "    # Merge legacy data with redcap visit data \n",
    "    print(\"-\"*50)\n",
    "    print(\"Merging redcap and legacy MoCA data\")\n",
    "    \n",
    "    redcap_moca_df = moca_df.loc[:, index_cols + list(moca_cols)]\n",
    "    n_redcap_participants = redcap_moca_df[\"Record ID:\"].nunique()\n",
    "    redcap_events = redcap_moca_df[\"Event Name\"].unique()\n",
    "    print(f\"Number of participants with redcap MoCA data: {n_redcap_participants}\")\n",
    "    print(f\"redcap_events MoCA data: {redcap_events}\")\n",
    "\n",
    "    redcap_and_legacy_moca_df = pd.concat([redcap_moca_df, legacy_moca_df], axis=0)\n",
    "    n_redcap_participants = redcap_and_legacy_moca_df[\"Record ID:\"].nunique()\n",
    "    redcap_events = redcap_and_legacy_moca_df[\"Event Name\"].unique()\n",
    "    print(f\"Number of participants with redcap and legacy MoCA data: {n_redcap_participants}\")\n",
    "    print(f\"redcap_events MoCA data: {redcap_events}\")\n",
    "\n",
    "    print(f\"Saving filtered legacy MoCA data to {collated_moca_file}\")\n",
    "    redcap_and_legacy_moca_df.to_csv(collated_moca_file, index=False)\n",
    "\n",
    "    legacy_moca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_vars = [\"dob\", \"enrollment_group\", \"sex\", \"education\"]\n",
    "# vars_with_secondary_source = [\"dob\"]\n",
    "\n",
    "config_json = demo_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "\n",
    "demo_var_df = pd.DataFrame()\n",
    "for var in demo_vars:\n",
    "    _df = get_available_data(config_json,data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "\n",
    "    if demo_var_df.empty:\n",
    "        demo_var_df = _df\n",
    "    else:\n",
    "        demo_var_df = pd.merge(demo_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "\n",
    "# add only DoB from seconday source\n",
    "var = \"dob\"\n",
    "print(f\"**Getting data from the secondary source for dob**\")\n",
    "legacy_dob_df = get_available_data(config_json,data_release_dir,var,preferred_var_source=\"secondary\")\n",
    "legacy_dob_df = legacy_dob_df.rename(columns=legacy_field_name_map)\n",
    "legacy_dob_df = legacy_dob_df.rename(columns={var:var+\"_secondary\"})\n",
    "\n",
    "participants_with_missing_value_in_primary = demo_var_df[(demo_var_df[\"redcap_event_name\"]==baseline_event_name) & (demo_var_df[var].isna())][\"participant_id\"].unique()\n",
    "legacy_dob_df = legacy_dob_df[legacy_dob_df[\"participant_id\"].isin(participants_with_missing_value_in_primary)].copy()\n",
    "\n",
    "demo_var_df = pd.merge(demo_var_df, legacy_dob_df, on=[\"participant_id\"], how=\"left\")\n",
    "demo_var_df[var] = demo_var_df[var].fillna(demo_var_df[\"dob_secondary\"])\n",
    "\n",
    "\n",
    "demo_participants = demo_var_df[\"participant_id\"].unique()\n",
    "n_demo_participants = len(demo_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with demographics data: {n_demo_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "demo_redcap_events = demo_var_df[\"redcap_event_name\"].unique()\n",
    "print(f\"Demographics data available for events: {demo_redcap_events}\")\n",
    "print('-'*50)\n",
    "\n",
    "# Only keep data for baseline event\n",
    "print('-'*50)\n",
    "print(f\"Keeping data for event: {baseline_event_name} (i.e. static variables)\")\n",
    "print(f\"All temporal data goes into assessment files\")\n",
    "print('-'*50)\n",
    "demo_var_df = demo_var_df[demo_var_df[\"redcap_event_name\"]==baseline_event_name].copy()\n",
    "\n",
    "for var in demo_vars:\n",
    "    n_unique = demo_var_df[var].nunique()\n",
    "    n_missing = demo_var_df[var].isna().sum()\n",
    "    print(f\"Var: {var}, n_unique: {n_unique}, n_missing: {n_missing} (out of {n_demo_participants})\")\n",
    "\n",
    "demo_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag / retract certain participants based on special criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Roche tag \n",
    "roche_participants_df = pd.read_csv(roche_participant_list_csv)\n",
    "roche_participants = roche_participants_df[\"participant_id\"].unique()\n",
    "\n",
    "print(f\"Number of Roche participants: {len(roche_participants)}\")\n",
    "\n",
    "demo_var_df[\"recruitment_cohort\"] = \"QPN\"\n",
    "demo_var_df.loc[demo_var_df[\"participant_id\"].isin(roche_participants),\"recruitment_cohort\"] = \"Roche\"\n",
    "\n",
    "demo_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save demographics data **without the DOB** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_save_cols = [\"participant_id\", \"redcap_event_name\", \"recruitment_cohort\", \"enrollment_group\", \"sex\", \"education\"]\n",
    "demo_var_without_dob_df = demo_var_df[demo_save_cols]\n",
    "demo_var_without_dob_df.to_csv(demographics_file, index=False)\n",
    "print(f\"Saved demographics data to {demographics_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find records with phenotypic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_vars = [\"updrs_scores\", \"moca_scores\", \"updrs_date\", \"moca_date\",\n",
    "              \"diagnosis_date\", \"diagnosis_confirmation\"] #\"legacy_updrs3_scores\", \"legacy_updrs3_date\",\n",
    "\n",
    "config_json = pheno_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "pheno_var_df = pd.DataFrame()\n",
    "for var in pheno_vars:\n",
    "    _df = get_available_data(config_json,data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "    if pheno_var_df.empty:\n",
    "        pheno_var_df = _df\n",
    "    else:\n",
    "        pheno_var_df = pd.merge(pheno_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "pheno_participants = pheno_var_df[\"participant_id\"].unique()\n",
    "n_pheno_participants = len(pheno_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with pheno data: {n_pheno_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "pheno_redcap_events = pheno_var_df[\"redcap_event_name\"].unique()\n",
    "print(f\"Pheno data available for events: {pheno_redcap_events}\")\n",
    "print('-'*50)\n",
    "\n",
    "for var in pheno_var_df.columns:\n",
    "    for redcap_event in pheno_redcap_events:\n",
    "        if var not in index_cols:\n",
    "            pheno_var_event_df = pheno_var_df[pheno_var_df[\"redcap_event_name\"]==redcap_event].copy()\n",
    "            n_pheno_var_event_participants = pheno_var_event_df[\"participant_id\"].nunique()\n",
    "            if pheno_var_event_df[var].nunique() > 0:    \n",
    "                print(f\"Var: {var}, Event: {redcap_event}\")\n",
    "                n_unique = pheno_var_event_df[var].nunique()\n",
    "                n_missing = pheno_var_event_df[var].isna().sum()\n",
    "                print(f\"n_unique: {n_unique}, n_missing: {n_missing} (out of {n_pheno_var_event_participants})\")\n",
    "    print('-'*50)\n",
    "\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag legacy participants for UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_vars = [\"legacy_updrs3_scores\", \"legacy_updrs3_date\"]\n",
    "\n",
    "config_json = pheno_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "legacy_var_df = pd.DataFrame()\n",
    "for var in pheno_vars:\n",
    "    _df = get_available_data(config_json,data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    # _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "    if legacy_var_df.empty:\n",
    "        legacy_var_df = _df\n",
    "    else:\n",
    "        legacy_var_df = pd.merge(legacy_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "n_legacy_participants = legacy_var_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants with legacy data: {n_legacy_participants}\")\n",
    "\n",
    "legacy_var_df[\"redcap_event_name\"] = \"legacy-updrs3\"\n",
    "legacy_var_df = legacy_var_df.rename(columns={\"legacy_updrs3_date\":\"updrs_date\"})\n",
    "\n",
    "# Append phono_var_df with legacy updrs data\n",
    "pheno_var_df = pd.concat([pheno_var_df, legacy_var_df], axis=0)\n",
    "\n",
    "legacy_var_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append legacy MoCA report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_vars = [\"legacy_moca_scores\", \"legacy_moca_date\"]\n",
    "\n",
    "config_json = pheno_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "legacy_var_df = pd.DataFrame()\n",
    "for var in pheno_vars:\n",
    "    _df = get_available_data(config_json,data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    # _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "    if legacy_var_df.empty:\n",
    "        legacy_var_df = _df\n",
    "    else:\n",
    "        legacy_var_df = pd.merge(legacy_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "n_legacy_participants = legacy_var_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants with legacy data: {n_legacy_participants}\")\n",
    "\n",
    "legacy_var_df[\"redcap_event_name\"] = \"legacy-moca\"\n",
    "legacy_var_df = legacy_var_df.rename(columns={\"legacy_moca_date\":\"moca_date\"})\n",
    "\n",
    "# Append phono_var_df with legacy updrs data\n",
    "pheno_var_df = pd.concat([pheno_var_df, legacy_var_df], axis=0)\n",
    "\n",
    "legacy_var_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign final Dx group label for analysis based on the following rules:\n",
    "\n",
    "1. if (in enrollment_report) enrollment_group  == 'Healthy control/Contrôle', then group = 'control'\n",
    "2. else (in the diagnosis report ) if determined_diagnosis == 0 & (final_impression == \"Meets criteria for Parkinson's disease / Répond aux critères de la maladie de Parkinson\") | final_impression == NA), then group = 'pd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_impression_col = \"Final impression / Impression finale\"\t\n",
    "determined_diagnosis_col = \"Determined diagnosis:  If score = 0, Parkinson's Disease (PD)  If score = 1, Progressive Supranuclear Palsy (PSP)  If score = 2, Multiple System Atrophy (MSA)  If score = 3, Corticobasal Syndrome (CBS)  If score = 4, Dementia with Lewy Bodies (DLB)  If score = 5, Frontotemporal Dementia (FTD)  If score = 6, Essential Tremor (ET)  If score = 7, REM Sleep Behaviour Disorder (RBD)\"\n",
    "final_impression_notes_for_PD = [\"Meets criteria for Parkinson's disease / Répond aux critères de la maladie de Parkinson\", np.nan]\n",
    "\n",
    "control_participants = demo_var_df[demo_var_df[\"enrollment_group\"]==\"Healthy control/Contrôle\"][\"participant_id\"].unique()\n",
    "PD_participants = pheno_var_df[(pheno_var_df[determined_diagnosis_col]==0) & (pheno_var_df[final_impression_col].isin(final_impression_notes_for_PD))][\"participant_id\"].unique()\n",
    "unknown_dx_participants = set(pheno_var_df[\"participant_id\"].unique()) - set(control_participants) - set(PD_participants)\n",
    "\n",
    "redcap_events_for_dx_confirmation = [baseline_event_name, \"legacy-updrs3\", \"legacy-moca\"]\n",
    "pheno_var_df[\"diagnosis_group_for_analysis\"] = np.nan\n",
    "pheno_var_df.loc[(pheno_var_df[\"participant_id\"].isin(control_participants)) & (pheno_var_df[\"redcap_event_name\"].isin(redcap_events_for_dx_confirmation)), \"diagnosis_group_for_analysis\"] = \"control\"\n",
    "pheno_var_df.loc[(pheno_var_df[\"participant_id\"].isin(PD_participants)) & (pheno_var_df[\"redcap_event_name\"].isin(redcap_events_for_dx_confirmation)), \"diagnosis_group_for_analysis\"] = \"PD\"\n",
    "pheno_var_df.loc[(pheno_var_df[\"participant_id\"].isin(unknown_dx_participants)) & (pheno_var_df[\"redcap_event_name\"].isin(redcap_events_for_dx_confirmation)), \"diagnosis_group_for_analysis\"] = \"unknown\"\n",
    "\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with diagnosis data: {len(pheno_var_df['participant_id'].unique())}\")\n",
    "print(f\"Number of control participants: {len(control_participants)}\")\n",
    "print(f\"Number of PD participants: {len(PD_participants)}\")\n",
    "print(f\"Number of unknown diagnosis participants: {len(unknown_dx_participants)}\")\n",
    "print('-'*50)\n",
    "\n",
    "pheno_var_df[index_cols + [\"diagnosis_group_for_analysis\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuropsych data\n",
    "- Comes from either from Sarah's extended report or BD_RPQ_UPDATE_Neuropsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsych_vars = [\"neuropsy_scores\",\"neuropsy_date\"]\n",
    "\n",
    "config_data = json.load(open(config_json))\n",
    "variable_info = config_data['variables'][neuropsych_vars[0]]\n",
    "variable_sources = variable_info[\"sources\"]\n",
    "neuropsy_source = variable_info['primary_source']\n",
    "\n",
    "print(f\"Using neuropsych data source: {neuropsy_source}\")\n",
    "# local BD_RPQ data\n",
    "if neuropsy_source == \"local\":\n",
    "    index_cols = [\"participant_id\", \"visit\", \"TimePoint (based on REDCap; baseline, 18m, 36m, etc.)\", \"Délai depuis baseline (mois)\"]\n",
    "    \n",
    "# redcap data\n",
    "if neuropsy_source == \"redcap\":\n",
    "    index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "\n",
    "    \n",
    "neuropsych_df = pd.DataFrame()\n",
    "for var in neuropsych_vars:\n",
    "    _df = get_available_data(config_json,data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "    if neuropsych_df.empty:\n",
    "        neuropsych_df = _df\n",
    "    else:\n",
    "        neuropsych_df = pd.merge(neuropsych_df, _df, on=index_cols, how=\"left\")   \n",
    "\n",
    "neuropsych_participants = neuropsych_df[\"participant_id\"].unique()\n",
    "n_neuropsych_participants = len(neuropsych_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with neuropysch data: {n_neuropsych_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "neuropsych_cols = neuropsych_df.columns.drop(index_cols).tolist()\n",
    "n_neuropsuch_cols = len(neuropsych_cols)\n",
    "print(f\"Neuropsych data available for variables: {n_neuropsuch_cols}\")\n",
    "print('-'*50)\n",
    "\n",
    "# BD_RPQ data\n",
    "if neuropsy_source == \"local\":\n",
    "    neuropsych_visits = neuropsych_df[\"visit\"].unique()\n",
    "\n",
    "# REDCap data\n",
    "if neuropsy_source == \"redcap\":\n",
    "    neuropsych_visits = neuropsych_df[\"redcap_event_name\"].unique()\n",
    "\n",
    "print(f\"neuropsych data available for events: {neuropsych_visits}\")\n",
    "print('-'*50)\n",
    "\n",
    "neuropsych_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic clean-up and data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix dtypes\n",
    "for series_name, series in neuropsych_df.items():\n",
    "    if \"score\" in series_name:\n",
    "        if series.dtype == 'object':\n",
    "            print(f\"recasting {series_name} to float by replacing , with .\")\n",
    "            neuropsych_df[series_name] = neuropsych_df[series_name].str.replace(\",\",\".\").astype(float)\n",
    "            neuropsych_df.loc[neuropsych_df[series_name]>900, series_name] = np.nan\n",
    "            \n",
    "    # Replace >900 with NaNs\n",
    "    if series.dtype == 'float':\n",
    "        neuropsych_df.loc[neuropsych_df[series_name]>900, series_name] = np.nan\n",
    "\n",
    "# assign redcap_event_name\n",
    "visit_months = [12, 18, 24, 30, 36, 42, 48, 54]\n",
    "month_bins = [9, 15, 21, 27, 33, 39, 45, 51, 57]\n",
    "event_str_suffix = \"Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "event_names = [f\"{m} {event_str_suffix}\" for m in visit_months]\n",
    "\n",
    "if neuropsy_source == \"local\":\n",
    "    neuropsych_df[\"redcap_event_name\"] = pd.cut(neuropsych_df[\"Délai depuis baseline (mois)\"], bins=month_bins, labels=event_names).astype(str)\n",
    "    neuropsych_df.loc[neuropsych_df[\"TimePoint (based on REDCap; baseline, 18m, 36m, etc.)\"]==\"baseline\", \n",
    "                      \"redcap_event_name\"] = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "# Merge with pheno_var_df\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "pheno_var_df = pd.merge(pheno_var_df, neuropsych_df, on=index_cols, how=\"left\")  \n",
    "\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add mri_acq date\n",
    "- Needs to map to redcap_event_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"MRI_date\"\n",
    "config_json = pheno_config_json\n",
    "mri_date_df = get_available_data(config_json,data_release_dir,var)\n",
    "mri_date_df[\"MRI_date\"] = pd.to_datetime(mri_date_df[\"MRI_date\"], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "n_mri_participants = mri_date_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants with MRI data: {n_mri_participants}\")\n",
    "\n",
    "n_sessions = mri_date_df[\"session\"].nunique()\n",
    "print(f\"Number of MRI sessions: {n_sessions}\")\n",
    "\n",
    "### Retracted participants\n",
    "print(f\"Removing retracted participants from the dataset\")\n",
    "retracted_participants_df = pd.read_csv(retracted_participant_list_csv)\n",
    "retracted_participants = retracted_participants_df[\"participant_id\"].unique()\n",
    "print(f\"removing following {len(retracted_participants)} participants from the dataset: {retracted_participants}\")\n",
    "mri_date_df = mri_date_df[~mri_date_df[\"participant_id\"].isin(retracted_participants)].copy()\n",
    "\n",
    "participants_with_follow_ups = mri_date_df[mri_date_df[\"participant_id\"].duplicated()][\"participant_id\"].unique()\n",
    "n_participants_with_follow_ups = len(participants_with_follow_ups)\n",
    "print(f\"Number of participants with follow-up MRI: {n_participants_with_follow_ups}\")\n",
    "\n",
    "mri_ses01_date_df = mri_date_df[mri_date_df[\"session\"]==\"ses-01\"].copy()\n",
    "mri_ses01_date_df[\"redcap_event_name\"] = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "mri_ses02_date_df = mri_date_df[mri_date_df[\"session\"]==\"ses-02\"].copy()\n",
    "mri_ses02_participants = mri_ses02_date_df[\"participant_id\"].unique()\n",
    "print(f\"Number of participants with ses-02 MRI: {len(mri_ses02_participants)}\")\n",
    "\n",
    "baseline_df = mri_ses01_date_df[mri_ses01_date_df[\"participant_id\"].isin(mri_ses02_participants)].set_index(\"participant_id\")\n",
    "followup_df = mri_ses02_date_df.set_index(\"participant_id\")\n",
    "\n",
    "visit_months = [12, 18, 24, 30, 36, 42, 48, 54]\n",
    "month_bins = [9, 15, 21, 27, 33, 39, 45, 51, 57]\n",
    "\n",
    "event_str_suffix = \"Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "event_names = [f\"{m} {event_str_suffix}\" for m in visit_months]\n",
    "\n",
    "# --- Bin the months --- #\n",
    "followup_df[\"months_since_baseline\"] = followup_df[\"MRI_date\"].dt.to_period('M').astype(int) - baseline_df[\"MRI_date\"].dt.to_period('M').astype(int)\n",
    "followup_df[\"months_since_baseline\"] = followup_df[\"months_since_baseline\"].replace({0:np.nan}) # Some visits get same acq_date from brodacasting merge. \n",
    "\n",
    "followup_df[\"redcap_event_name\"] = pd.cut(followup_df[\"months_since_baseline\"], bins=month_bins, labels=event_names)\n",
    "\n",
    "mri_date_redcap_event_df = pd.concat([mri_ses01_date_df, followup_df.reset_index()], axis=0)\n",
    "# mri_date_redcap_event_df = mri_date_redcap_event_df\n",
    "\n",
    "mri_date_redcap_event_df.sort_values([\"participant_id\",\"session\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add MRI date to pheno data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_date_redcap_event_df[mri_date_redcap_event_df[\"MRI_date\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_var_df = pd.merge(pheno_var_df, mri_date_redcap_event_df, on=index_cols, how=\"outer\")  \n",
    "var = \"MRI_date\"\n",
    "for redcap_event in mri_date_redcap_event_df[\"redcap_event_name\"].unique():    \n",
    "    pheno_var_event_df = pheno_var_df[pheno_var_df[\"redcap_event_name\"]==redcap_event].copy()\n",
    "    n_pheno_var_event_participants = pheno_var_event_df[\"participant_id\"].nunique()\n",
    "    if pheno_var_event_df[var].nunique() > 0:    \n",
    "        print(f\"Var: {var}, Event: {redcap_event}\")\n",
    "        n_unique = pheno_var_event_df[var].nunique()\n",
    "        n_missing = pheno_var_event_df[var].isna().sum()\n",
    "        print(f\"n_unique: {n_unique}, n_missing: {n_missing} (out of {n_pheno_var_event_participants})\")\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_cols = [\"participant_id\", \"dob\", \"enrollment_group\", \"sex\"]\n",
    "demo_var_df[demo_var_df[\"participant_id\"]==participants_with_follow_ups[0]]\n",
    "baseline_demo_df = demo_var_df[demo_var_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"][demo_cols].copy()\n",
    "\n",
    "index_cols = [\"participant_id\"] # not using redcap_event_name to allow broadcast of demographics vars\n",
    "tabular_df = pd.merge(pheno_var_df, baseline_demo_df, on=index_cols, how=\"left\")\n",
    "tabular_df[tabular_df[\"participant_id\"]==participants_with_follow_ups[0]]\n",
    "\n",
    "tabular_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_cols = [\"diagnosis_date\", \"updrs_date\", \"moca_date\", \"MRI_date\", \"neuropsy_date\"]\n",
    "\n",
    "date_age_cols_dict = {}\n",
    "for col in date_cols:\n",
    "    date_age_cols_dict[col] = f\"{col.rsplit('_',1)[0]}_age\"\n",
    "\n",
    "age_cols = list(date_age_cols_dict.values())\n",
    "\n",
    "for date_col, age_col in date_age_cols_dict.items():\n",
    "    tabular_df = get_age_at_visit(tabular_df, date_col, age_col)\n",
    "\n",
    "tabular_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save demo, mri_dates, and pheno (dx, updrs, moca, neuropsych) in separate files\n",
    "- remove DoB and other date columns \n",
    "- add age columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "\n",
    "mri_cols = [\"session\", \"MRI_age\"]\n",
    "\n",
    "dx_cols = ['Hoehn and Yahr Stage: ',            \n",
    "           \"Parkinson's disease in opinion of treating neurologist / Maladie de Parkinson selon l'avis du neurologue traitant\",\n",
    "            \"Final impression / Impression finale\",\t\n",
    "            \"Determined diagnosis:  If score = 0, Parkinson's Disease (PD)  If score = 1, Progressive Supranuclear Palsy (PSP)  If score = 2, Multiple System Atrophy (MSA)  If score = 3, Corticobasal Syndrome (CBS)  If score = 4, Dementia with Lewy Bodies (DLB)  If score = 5, Frontotemporal Dementia (FTD)  If score = 6, Essential Tremor (ET)  If score = 7, REM Sleep Behaviour Disorder (RBD)\",\n",
    "            \"diagnosis_group_for_analysis\",\n",
    "            \"diagnosis_age\"\n",
    "            ]\n",
    "\n",
    "updrs_cols = ['Part I: Non-Motor Aspects of Experiences of Daily Living (nM-EDL)',\n",
    "              'Part II: Motor Aspects of Experiences of Daily Living (M-EDL)',\n",
    "              \"Updrs_3_1 value\", \"Updrs_3_2 value\", \"Updrs_3_3_neck value\",\n",
    "              \"Updrs_3_3_rue value\", \"Updrs_3_3_lue value\", \"Updrs_3_3_rle value\",\n",
    "              \"Updrs_3_3_lle value\", \"Updrs_3_4_r value\", \"Updrs_3_4_l value\",\n",
    "              \"Updrs_3_5_r value\", \"Updrs_3_5_l value\", \"Updrs_3_6_r value\",\n",
    "              \"Updrs_3_6_l value\", \"Updrs_3_7_r value\", \"Updrs_3_7_l value\",\n",
    "              \"Updrs_3_8_r value\", \"Updrs_3_8_l value\", \"Updrs_3_9 value\",\n",
    "              \"Updrs_3_10 value\", \"Updrs_3_11 value\", \"Updrs_3_12 value\",\n",
    "              \"Updrs_3_13 value\", \"Updrs_3_14\", \"Updrs_3_15_r value\",\n",
    "              \"Updrs_3_15_l value\", \"Updrs_3_16_r value\", \"Updrs_3_16_l value\",\n",
    "              \"Updrs_3_17_rue value\", \"Updrs_3_17_lue value\", \"Updrs_3_17_rle value\",\n",
    "              \"Updrs_3_17_lle value\", \"Updrs_3_17_lipjaw value\", \"Updrs_3_18 value\",\n",
    "              'Part III: Motor Examination', 'Part IV: Motor Complications', \n",
    "              'updrs_age',\n",
    "              ]\n",
    "\n",
    "# moca_cols = [\"moca_scores\", \"moca_age\"]\n",
    "moca_cols = [\n",
    "            \"TOTAL SCORE (make sure to include extra point for 12 years or less of education):    SCORE TOTAL (assurez-vous d'inclure un point supplémentaire pour 12 ans ou moins d'éducation) : \",\n",
    "            \"Did the participant receive +1 extra point for 12 years or less of education?    Le participant a-t-il reçu +1 point supplémentaire pour 12 ans ou moins d'études?\",\n",
    "            \"moca_age\"\n",
    "            ]\n",
    "\n",
    "neuropsych_cols = neuropsych_cols + [\"neuropsy_age\"]\n",
    "if \"neuropsy_date\" in neuropsych_cols:\n",
    "    neuropsych_cols.remove(\"neuropsy_date\")\n",
    "\n",
    "mri_df = tabular_df[index_cols + mri_cols]\n",
    "dx_df = tabular_df[index_cols + dx_cols].copy()\n",
    "updrs_df = tabular_df[index_cols + updrs_cols].copy()\n",
    "moca_df = tabular_df[index_cols + moca_cols].copy()\n",
    "neuropsych_df = tabular_df[index_cols + neuropsych_cols].copy()\n",
    "\n",
    "# filter na rows\n",
    "mri_df = mri_df.dropna(subset=mri_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "dx_df = dx_df.dropna(subset=dx_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "updrs_df = updrs_df.dropna(subset=updrs_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "moca_df = moca_df.dropna(subset=moca_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "neuropsych_df = neuropsych_df.dropna(subset=neuropsych_cols, how='all').sort_values([\"redcap_event_name\"], ascending=False).sort_values([\"participant_id\"])\n",
    "\n",
    "\n",
    "# Save data to files\n",
    "mri_df.to_csv(mri_session_date_file, index=False)\n",
    "print(f\"Saved MRI session data to {mri_session_date_file}\")\n",
    "\n",
    "dx_df.to_csv(dx_file, index=False)\n",
    "print(f\"Saved diagnosis data to {dx_file}\")\n",
    "\n",
    "updrs_df.to_csv(updrs_file, index=False)\n",
    "print(f\"Saved UPDRS data to {updrs_file}\")\n",
    "\n",
    "moca_df.to_csv(moca_file, index=False)\n",
    "print(f\"Saved MoCA data to {moca_file}\")\n",
    "\n",
    "neuropsych_df.to_csv(neuropsych_file, index=False)\n",
    "print(f\"Saved neuropsych data to {neuropsych_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_dx_df = pd.merge(mri_df[[\"participant_id\",\"session\"]], dx_df[[\"participant_id\",\"diagnosis_group_for_analysis\"]], on=[\"participant_id\"], how=\"left\").drop_duplicates()\n",
    "mri_dx_df = pd.merge(mri_dx_df, demo_var_df[[\"participant_id\", \"recruitment_cohort\", \"enrollment_group\"]], on=[\"participant_id\"], how=\"left\").drop_duplicates()\n",
    "mri_dx_df.groupby([\"session\", \"recruitment_cohort\", \"enrollment_group\", \"diagnosis_group_for_analysis\"]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark NM participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NM_participants_df = pd.read_csv(neuromelanin_participant_list_csv)\n",
    "NM_participants_df = NM_participants_df.rename(columns={\"PSCID\":\"participant_id\"})\n",
    "NM_participants = NM_participants_df[\"participant_id\"].unique()\n",
    "print(f\"Number of Neuromelanin participants: {len(NM_participants)}\")\n",
    "\n",
    "NM_participants_df.loc[NM_participants_df[\"Visit Label\"] == \"MRI01\", \"session\"] = \"ses-01\"\n",
    "NM_participants_df.loc[NM_participants_df[\"Visit Label\"] == \"MRI02\", \"session\"] = \"ses-02\"\n",
    "NM_participants_df.loc[NM_participants_df[\"Visit Label\"] == \"MRI03\", \"session\"] = \"ses-03\"\n",
    "\n",
    "# session wise counts\n",
    "session_counts = NM_participants_df[\"session\"].value_counts()\n",
    "print(f\"session_counts: {session_counts}\")\n",
    "\n",
    "# compare with mri_df\n",
    "mri_participants = mri_df[\"participant_id\"].unique()\n",
    "print(f\"Number of participants with MRI data: {len(mri_participants)}\")\n",
    "\n",
    "# participants in NM cohort but not in MRI cohort\n",
    "NM_participants_not_in_mri = set(NM_participants) - set(mri_participants)\n",
    "print(f\"Number of NM participants not in MRI cohort: {len(NM_participants_not_in_mri)}\")\n",
    "\n",
    "# participants in NM cohort and in MRI cohort\n",
    "NM_participants_in_mri = set(NM_participants) & set(mri_participants)\n",
    "print(f\"Number of NM participants in MRI cohort: {len(NM_participants_in_mri)}\")\n",
    "\n",
    "# participants in MRI cohort but not in NM cohort\n",
    "mri_participants_not_in_NM = set(mri_participants) - set(NM_participants)\n",
    "print(f\"Number of MRI participants not in NM cohort: {len(mri_participants_not_in_NM)}\")\n",
    "\n",
    "# save NM participants\n",
    "NM_participants_df.to_csv(f\"{tabular_data_release_dir}/recruitment/neuromelanin_participants_VM.csv\", index=False)\n",
    "\n",
    "NM_participants_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipoppy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
