{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "from dateutil import relativedelta\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API call for redcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def api_call(url, query, logger=None):\n",
    "    \"\"\" helper function to make API calls to RedCap\n",
    "    \"\"\"\n",
    "    r = requests.post(url, data=query, verify=False)\n",
    "    http_status = str(r.status_code)\n",
    "    print(f'HTTP Status: {http_status}')\n",
    "\n",
    "    if http_status == \"200\":\n",
    "        query_results = r.json()\n",
    "        query_df = pd.DataFrame(query_results)\n",
    "\n",
    "    else:\n",
    "        print(f\"RedCap API request Failed with HTTP Status: {http_status}\")\n",
    "        query_df = None\n",
    "        \n",
    "    return query_df\n",
    "\n",
    "def get_inventory_count(df, index_col, availability_indicators):\n",
    "    \"\"\" helper function to count participants with recorded data in redcap\n",
    "    \"\"\"\n",
    "    assess_cols = df.columns.drop(index_col)\n",
    "\n",
    "    if availability_indicators == 'number':\n",
    "        df = df.replace(\"\", np.nan)\n",
    "        df[assess_cols] = df[assess_cols].astype(np.float64)\n",
    "\n",
    "    inventory = {}\n",
    "    for col in assess_cols:        \n",
    "        if availability_indicators == 'number':\n",
    "            availability_count = df[~df[col].isna()][index_col].nunique()\n",
    "        else:\n",
    "            availability_count = df[df[col].isin(availability_indicators)][index_col].nunique()\n",
    "        inventory[col] = availability_count\n",
    "    return inventory\n",
    "\n",
    "def get_available_data(config_json, DATASET_ROOT, var_name, preferred_var_source=\"primary\"):\n",
    "    \"\"\" Get data for given variables from available sources\n",
    "        All return dataframes should have participant_id and visit_id as index\n",
    "    \"\"\"\n",
    "    config_data = json.load(open(config_json))\n",
    "    data_sources = config_data['data_sources']\n",
    "    variable_info = config_data['variables'][var_name]\n",
    "    variable_type = variable_info[\"type\"]\n",
    "    variable_sources = variable_info[\"sources\"]\n",
    "\n",
    "    if preferred_var_source == \"primary\":\n",
    "        selected_var_source = variable_info['primary_source']\n",
    "        selected_var_instrument = variable_info['primary_instrument']\n",
    "    elif preferred_var_source == \"secondary\":\n",
    "        selected_var_source = variable_info['secondary_source']\n",
    "        selected_var_instrument = variable_info['secondary_instrument']\n",
    "    else:\n",
    "        print(f\"Using preferred source {preferred_var_source} for variable {var_name}\")\n",
    "        preferred_var_data_source = preferred_var_source[\"data_source\"]\n",
    "        preferred_var_instrument = preferred_var_source[\"instrument\"]\n",
    "\n",
    "        if preferred_var_data_source not in variable_sources.keys():\n",
    "            print(f\"Preferred data source {preferred_var_data_source} not available for variable {var_name}\")\n",
    "            return None\n",
    "        else:\n",
    "            selected_var_source = preferred_var_data_source\n",
    "\n",
    "        if preferred_var_instrument not in variable_sources[selected_var_source].keys():\n",
    "            print(f\"Preferred var instrument {preferred_var_instrument} not available for variable {var_name}\")\n",
    "            return None\n",
    "        else:\n",
    "            selected_var_instrument = preferred_var_instrument\n",
    "\n",
    "    print(f\"Using variable {var_name} from source {selected_var_source} and instrument {selected_var_instrument}\")\n",
    "\n",
    "    external_var_cols = variable_sources[selected_var_source][selected_var_instrument]\n",
    "\n",
    "    # Get data from primary source\n",
    "    var_file = data_sources[selected_var_source][selected_var_instrument][\"path\"]\n",
    "    var_file_path = f\"{DATASET_ROOT}/{var_file}\"\n",
    "    var_file_index = data_sources[selected_var_source][selected_var_instrument][\"index_cols\"]\n",
    "\n",
    "    var_df = pd.read_csv(var_file_path)\n",
    "    selected_var_cols = list(set(var_file_index + external_var_cols))\n",
    "    var_df = var_df[selected_var_cols]\n",
    "    \n",
    "    if (variable_type == \"date\") & (len(external_var_cols) == 1):\n",
    "        var_df[external_var_cols[0]] = pd.to_datetime(var_df[external_var_cols[0]], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "    if (len(external_var_cols) == 1):\n",
    "        var_df = var_df.rename(columns={external_var_cols[0]:var_name})\n",
    "    \n",
    "    return var_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"/home/nikhil/projects/Parkinsons/qpn/\"\n",
    "\n",
    "# Current nipoppy manifest\n",
    "release_dir = f\"{DATASET_ROOT}/releases/\"\n",
    "current_release = \"Jan_2024\"\n",
    "\n",
    "tabular_data_release_dir = f\"{release_dir}/{current_release}/\"\n",
    "\n",
    "demo_config_json = \"../workflow/tabular/demographics.json\"\n",
    "pheno_config_json = \"../workflow/tabular/pheno.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized index names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_event_name = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "## redcap event name variations\n",
    "config_data = json.load(open(demo_config_json))\n",
    "data_sources = config_data['data_sources']\n",
    "redcap_data_sources = data_sources['redcap']\n",
    "\n",
    "redcap_field_name_map = {}\n",
    "\n",
    "for instrument in redcap_data_sources.keys():\n",
    "    index_cols = redcap_data_sources[instrument]['index_cols']\n",
    "    record_id = index_cols[0]\n",
    "    event_name = index_cols[1]\n",
    "\n",
    "    redcap_field_name_map[record_id] = \"participant_id\"\n",
    "    redcap_field_name_map[event_name] = \"redcap_event_name\"\n",
    "print(f\"redcap_field_name_map: {redcap_field_name_map}\")\n",
    "\n",
    "# legacy participant_id variations in DOB and BD_RPQ\n",
    "legacy_field_name_map = {}\n",
    "legacy_field_name_map['Record ID'] = \"participant_id\"\n",
    "legacy_field_name_map['Patient #'] = \"participant_id\"\n",
    "legacy_field_name_map['Name of visit (V01, V02, V03)'] = \"visit\"\n",
    "print(f\"legacy_field_name_map: {legacy_field_name_map}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update RedCAP reports through API \n",
    "(Not updating extended report since it has to come from Sarah)\n",
    "- \"global_records_query\"\n",
    "- \"QPN MoCA-UPDRS-Neuropsy data_Sarah\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_redcap_reports = False\n",
    "\n",
    "redcap_report_list = [\"global_records_query\", \"QPN MoCA-UPDRS-Neuropsy data_Sarah\"]\n",
    "if update_redcap_reports:\n",
    "    redcap_config_json = f\"{DATASET_ROOT}/proc/.redcap.json\"\n",
    "    redcap_config = json.load(open(redcap_config_json))\n",
    "    url = redcap_config[\"url\"]\n",
    "    \n",
    "    for redcap_report in redcap_report_list:\n",
    "        print(f\"Getting data for RedCap report: {redcap_report}\")\n",
    "        records_query = redcap_config[\"queries\"][redcap_report]\n",
    "        query_df = api_call(url, records_query, logger=None)\n",
    "        report_csv = f\"{release_dir}{current_release}/tabular/redcap/{redcap_report}.csv\"\n",
    "        query_df.to_csv(report_csv, index=False)\n",
    "        print(f\"Saved RedCap report to {report_csv}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QPN_participants_df = get_available_data(demo_config_json,tabular_data_release_dir,\"participant_id\")\n",
    "QPN_participants = QPN_participants_df[\"participant_id\"].unique()\n",
    "n_participants = len(QPN_participants)\n",
    "print(f\"Number of participants: {n_participants}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_vars = [\"dob\", \"group\", \"sex\"]\n",
    "# preferred_var_source = {\"data_source\":\"local\",\"instrument\":\"legacy_DOB\"}\n",
    "vars_with_secondary_source = [\"dob\"]\n",
    "\n",
    "config_json = demo_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "\n",
    "demo_var_df = pd.DataFrame()\n",
    "for var in demo_vars:\n",
    "    _df = get_available_data(config_json,tabular_data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "\n",
    "    if var in vars_with_secondary_source:\n",
    "        print(f\"**Getting data from the secondary source for variable {var}**\")\n",
    "        _df2 = get_available_data(config_json,tabular_data_release_dir,var,preferred_var_source=\"secondary\")\n",
    "        _df2 = _df2.rename(columns=legacy_field_name_map)\n",
    "        _df2 = _df2.rename(columns={var:var+\"_secondary\"})\n",
    "        _df2 = _df2[_df2[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "        \n",
    "        # Merge primary and secondary sources\n",
    "        n_missing_in_primary = _df[_df[\"redcap_event_name\"]==baseline_event_name][var].isna().sum()\n",
    "        print(f\"Missing data in primary source: {n_missing_in_primary}\")\n",
    "\n",
    "        if \"redcap_event_name\" in _df2.columns:\n",
    "            _df = pd.merge(_df, _df2, on=[\"participant_id\",\"redcap_event_name\"], how=\"outer\")\n",
    "        else:\n",
    "            _df = pd.merge(_df, _df2, on=\"participant_id\", how=\"outer\")\n",
    "        _df[var] = _df[var].fillna(_df[var+\"_secondary\"])\n",
    "        # _df = _df.drop(columns=[var+\"_secondary\"])\n",
    "\n",
    "        n_missing_after_secondary_fill = _df[_df[\"redcap_event_name\"]==baseline_event_name][var].isna().sum()\n",
    "        print(f\"Missing data after secondary source fill: {n_missing_after_secondary_fill}\")\n",
    "\n",
    "    if demo_var_df.empty:\n",
    "        demo_var_df = _df\n",
    "    else:\n",
    "        demo_var_df = pd.merge(demo_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "demo_participants = demo_var_df[\"participant_id\"].unique()\n",
    "n_demo_participants = len(demo_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with demographics data: {n_demo_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "demo_redcap_events = demo_var_df[\"redcap_event_name\"].unique()\n",
    "print(f\"Demographics data available for events: {demo_redcap_events}\")\n",
    "print('-'*50)\n",
    "\n",
    "for var in demo_vars:\n",
    "    n_unique = demo_var_df[demo_var_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"][var].nunique()\n",
    "    n_missing = demo_var_df[demo_var_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"][var].isna().sum()\n",
    "    print(f\"Var: {var}, n_unique: {n_unique}, n_missing: {n_missing} (out of {n_demo_participants})\")\n",
    "\n",
    "demo_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find records with phenotypic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_vars = [\"diagnosis\", \"updrs_scores\", \"moca_scores\", \"diagnosis_date\", \"updrs_date\", \"moca_date\"]\n",
    "# preferred_var_source = {\"data_source\":\"local\",\"instrument\":\"legacy_DOB\"}\n",
    "\n",
    "config_json = pheno_config_json\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "pheno_var_df = pd.DataFrame()\n",
    "for var in pheno_vars:\n",
    "    _df = get_available_data(config_json,tabular_data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "    if pheno_var_df.empty:\n",
    "        pheno_var_df = _df\n",
    "    else:\n",
    "        pheno_var_df = pd.merge(pheno_var_df, _df, on=index_cols, how=\"outer\")   \n",
    "\n",
    "pheno_participants = pheno_var_df[\"participant_id\"].unique()\n",
    "n_pheno_participants = len(pheno_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with pheno data: {n_pheno_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "pheno_redcap_events = pheno_var_df[\"redcap_event_name\"].unique()\n",
    "print(f\"Pheno data available for events: {pheno_redcap_events}\")\n",
    "print('-'*50)\n",
    "\n",
    "for var in pheno_var_df.columns:\n",
    "    for redcap_event in pheno_redcap_events:\n",
    "        if var not in index_cols:\n",
    "            pheno_var_event_df = pheno_var_df[pheno_var_df[\"redcap_event_name\"]==redcap_event].copy()\n",
    "            n_pheno_var_event_participants = pheno_var_event_df[\"participant_id\"].nunique()\n",
    "            if pheno_var_event_df[var].nunique() > 0:    \n",
    "                print(f\"Var: {var}, Event: {redcap_event}\")\n",
    "                n_unique = pheno_var_event_df[var].nunique()\n",
    "                n_missing = pheno_var_event_df[var].isna().sum()\n",
    "                print(f\"n_unique: {n_unique}, n_missing: {n_missing} (out of {n_pheno_var_event_participants})\")\n",
    "    print('-'*50)\n",
    "\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add mri_acq date\n",
    "- Needs to map to redcap_event_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"MRI_date\"\n",
    "config_json = pheno_config_json\n",
    "mri_date_df = get_available_data(config_json,tabular_data_release_dir,var)\n",
    "mri_date_df[\"MRI_date\"] = pd.to_datetime(mri_date_df[\"MRI_date\"], errors=\"coerce\", dayfirst=False)\n",
    "\n",
    "n_mri_participants = mri_date_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants with MRI data: {n_mri_participants}\")\n",
    "\n",
    "n_sessions = mri_date_df[\"session\"].nunique()\n",
    "print(f\"Number of MRI sessions: {n_sessions}\")\n",
    "\n",
    "participants_with_follow_ups = mri_date_df[mri_date_df[\"participant_id\"].duplicated()][\"participant_id\"].unique()\n",
    "n_participants_with_follow_ups = len(participants_with_follow_ups)\n",
    "print(f\"Number of participants with follow-up MRI: {n_participants_with_follow_ups}\")\n",
    "\n",
    "mri_ses01_date_df = mri_date_df[mri_date_df[\"session\"]==\"ses-01\"].copy()\n",
    "mri_ses01_date_df[\"redcap_event_name\"] = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "mri_ses02_date_df = mri_date_df[mri_date_df[\"session\"]==\"ses-02\"].copy()\n",
    "mri_ses02_participants = mri_ses02_date_df[\"participant_id\"].unique()\n",
    "print(f\"Number of participants with ses-02 MRI: {len(mri_ses02_participants)}\")\n",
    "\n",
    "baseline_df = mri_ses01_date_df[mri_ses01_date_df[\"participant_id\"].isin(mri_ses02_participants)].set_index(\"participant_id\")\n",
    "followup_df = mri_ses02_date_df.set_index(\"participant_id\")\n",
    "\n",
    "visit_months = [12, 18, 24, 30, 36, 42, 48, 54]\n",
    "month_bins = [9, 15, 21, 27, 33, 39, 45, 51, 57]\n",
    "\n",
    "event_str_suffix = \"Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "event_names = [f\"{m} {event_str_suffix}\" for m in visit_months]\n",
    "\n",
    "# --- Bin the months --- #\n",
    "followup_df[\"months_since_baseline\"] = followup_df[\"MRI_date\"].dt.to_period('M').astype(int) - baseline_df[\"MRI_date\"].dt.to_period('M').astype(int)\n",
    "followup_df[\"months_since_baseline\"] = followup_df[\"months_since_baseline\"].replace({0:np.nan}) # Some visits get same acq_date from brodacasting merge. \n",
    "\n",
    "followup_df[\"redcap_event_name\"] = pd.cut(followup_df[\"months_since_baseline\"], bins=month_bins, labels=event_names)\n",
    "\n",
    "mri_date_redcap_event_df = pd.concat([mri_ses01_date_df, followup_df.reset_index()], axis=0)\n",
    "# mri_date_redcap_event_df = mri_date_redcap_event_df\n",
    "\n",
    "mri_date_redcap_event_df.sort_values([\"participant_id\",\"session\"]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add MRI date to pheno data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pheno_var_df = pd.merge(pheno_var_df, mri_date_redcap_event_df, on=index_cols, how=\"right\")  \n",
    "var = \"MRI_date\"\n",
    "for redcap_event in mri_date_redcap_event_df[\"redcap_event_name\"].unique():    \n",
    "    pheno_var_event_df = pheno_var_df[pheno_var_df[\"redcap_event_name\"]==redcap_event].copy()\n",
    "    n_pheno_var_event_participants = pheno_var_event_df[\"participant_id\"].nunique()\n",
    "    if pheno_var_event_df[var].nunique() > 0:    \n",
    "        print(f\"Var: {var}, Event: {redcap_event}\")\n",
    "        n_unique = pheno_var_event_df[var].nunique()\n",
    "        n_missing = pheno_var_event_df[var].isna().sum()\n",
    "        print(f\"n_unique: {n_unique}, n_missing: {n_missing} (out of {n_pheno_var_event_participants})\")\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neuropsych data\n",
    "- Comes from either from Sarah's extended report or BD_RPQ_UPDATE_Neuropsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuropsych_vars = [\"neuropsy_scores\",\"neuropsy_date\"]\n",
    "\n",
    "index_cols = [\"participant_id\", \"visit\", \"TimePoint (based on REDCap; baseline, 18m, 36m, etc.)\", \"Délai depuis baseline (mois)\"]\n",
    "neuropsych_df = pd.DataFrame()\n",
    "for var in neuropsych_vars:\n",
    "    _df = get_available_data(config_json,tabular_data_release_dir,var)\n",
    "    _df = _df.rename(columns=redcap_field_name_map)\n",
    "    _df = _df.rename(columns=legacy_field_name_map)\n",
    "    _df = _df[_df[\"participant_id\"].isin(QPN_participants)].copy()\n",
    "    if neuropsych_df.empty:\n",
    "        neuropsych_df = _df\n",
    "    else:\n",
    "        neuropsych_df = pd.merge(neuropsych_df, _df, on=index_cols, how=\"left\")   \n",
    "\n",
    "neuropsych_participants = neuropsych_df[\"participant_id\"].unique()\n",
    "n_neuropsych_participants = len(neuropsych_participants)\n",
    "print('-'*50)\n",
    "print(f\"Number of participants with neuropysch data: {n_neuropsych_participants}\")\n",
    "print('-'*50)\n",
    "\n",
    "neuropsych_visits = neuropsych_df[\"visit\"].unique()\n",
    "print(f\"neuropsych data available for events: {neuropsych_visits}\")\n",
    "print('-'*50)\n",
    "\n",
    "neuropsych_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic clean-up and data checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix dtypes\n",
    "for series_name, series in neuropsych_df.items():\n",
    "    if \"score\" in series_name:\n",
    "        if series.dtype == 'object':\n",
    "            print(f\"recasting {series_name} to float by replacing , with .\")\n",
    "            neuropsych_df[series_name] = neuropsych_df[series_name].str.replace(\",\",\".\").astype(float)\n",
    "            neuropsych_df.loc[neuropsych_df[series_name]>900, series_name] = np.nan\n",
    "            \n",
    "    # Replace >900 with NaNs\n",
    "    if series.dtype == 'float':\n",
    "        neuropsych_df.loc[neuropsych_df[series_name]>900, series_name] = np.nan\n",
    "\n",
    "# assign redcap_event_name\n",
    "visit_months = [12, 18, 24, 30, 36, 42, 48, 54]\n",
    "month_bins = [9, 15, 21, 27, 33, 39, 45, 51, 57]\n",
    "event_str_suffix = \"Months Follow-Up/Suivi (Arm 1: C-OPN)\"\n",
    "event_names = [f\"{m} {event_str_suffix}\" for m in visit_months]\n",
    "\n",
    "neuropsych_df[\"redcap_event_name\"] = pd.cut(neuropsych_df[\"Délai depuis baseline (mois)\"], bins=month_bins, labels=event_names).astype(str)\n",
    "neuropsych_df.loc[neuropsych_df[\"TimePoint (based on REDCap; baseline, 18m, 36m, etc.)\"]==\"baseline\", \n",
    "                  \"redcap_event_name\"] = \"Baseline (Arm 1: C-OPN)\"\n",
    "\n",
    "# Merge with pheno_var_df\n",
    "index_cols = [\"participant_id\", \"redcap_event_name\"]\n",
    "pheno_var_df = pd.merge(pheno_var_df, neuropsych_df, on=index_cols, how=\"left\")  \n",
    "\n",
    "pheno_var_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_cols = [\"participant_id\", \"dob\", \"group\", \"sex\"]\n",
    "demo_var_df[demo_var_df[\"participant_id\"]==participants_with_follow_ups[0]]\n",
    "baseline_demo_df = demo_var_df[demo_var_df[\"redcap_event_name\"]==\"Baseline (Arm 1: C-OPN)\"][demo_cols].copy()\n",
    "\n",
    "index_cols = [\"participant_id\"] # not using redcap_event_name to allow broadcast of demographics vars\n",
    "tabular_df = pd.merge(pheno_var_df, baseline_demo_df, on=index_cols, how=\"left\")\n",
    "tabular_df[tabular_df[\"participant_id\"]==participants_with_follow_ups[0]]\n",
    "\n",
    "tabular_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_at_visit(df, var, dob_col=\"dob\", rounding_digits=2, age_range=(0,100)):\n",
    "    \"\"\" Get age at visit. Expects column name to be: var_date \"\"\"\n",
    "    \n",
    "    age_col = var.split(\"_\")[0]+\"_age\"\n",
    "    df[age_col] = df[var] - tabular_df[dob_col]\n",
    "    df[age_col] = np.round(df[age_col].dt.days / 365.25, rounding_digits)\n",
    "\n",
    "    if (len(df[df[age_col] > 100]) | len(df[df[age_col] < 0])):\n",
    "        print(f\"Warning: Age values outside range {age_range} for variable {var}\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_vars = [\"diagnosis_date\", \"updrs_date\", \"moca_date\", \"MRI_date\", \"neuropsy_date\"]\n",
    "\n",
    "for age_var in age_vars:\n",
    "    tabular_df = get_age_at_visit(tabular_df, age_var)\n",
    "\n",
    "tabular_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QPN paper tables\n",
    "\n",
    "#### Demo table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_vars = [\"participant_id\", \"redcap_event_name\", \"MRI_age\", \"sex\", \"group\"]\n",
    "redcap_events = [\"Baseline (Arm 1: C-OPN)\",\"12 Months Follow-Up/Suivi (Arm 1: C-OPN)\",\"18 Months Follow-Up/Suivi (Arm 1: C-OPN)\"]\n",
    "QPN_groups = {\"Healthy control/Contrôle\": \"control\", \n",
    "              \"PD   (Parkinson's Disease)/Maladie de Parkinson\": \"PD\"}\n",
    "QPN_sexes = {\"Female/Féminin\": \"Female\", \"Male/Masculin\":\"Male\"}\n",
    "n_tabular_participants = tabular_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants: {n_tabular_participants}\")\n",
    "\n",
    "demo_df = tabular_df[(tabular_df[\"redcap_event_name\"].isin(redcap_events)) & \n",
    "                     (tabular_df[\"group\"].isin(QPN_groups.keys()))][demo_vars].copy()\n",
    "\n",
    "demo_df[\"group\"] = demo_df[\"group\"].replace(QPN_groups)\n",
    "demo_df[\"sex\"] = demo_df[\"sex\"].replace(QPN_sexes)\n",
    "\n",
    "n_participants = demo_df[\"participant_id\"].nunique()\n",
    "print(f\"Number of participants after event and group filter: {n_participants}\")\n",
    "\n",
    "demo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counts\n",
    "global_count_df = demo_df.groupby([\"redcap_event_name\"])[\"MRI_age\"].count().reset_index()\n",
    "global_count_df = global_count_df.rename(columns={\"MRI_age\":\"n_participants\"})\n",
    "\n",
    "# age\n",
    "mean_age_df = demo_df.groupby([\"redcap_event_name\"])[\"MRI_age\"].mean().round(1).reset_index()\n",
    "std_age_df = demo_df.groupby([\"redcap_event_name\"])[\"MRI_age\"].std().round(1).reset_index()\n",
    "\n",
    "demo_table_df = pd.merge(global_count_df, mean_age_df, on=\"redcap_event_name\")\n",
    "demo_table_df = pd.merge(demo_table_df, std_age_df, on=\"redcap_event_name\", suffixes=('_mean', '_std'))\n",
    "\n",
    "# sex\n",
    "sex_count_df = demo_df.groupby([\"redcap_event_name\"])[\"sex\"].value_counts().unstack().reset_index()\n",
    "demo_table_df = pd.merge(demo_table_df, sex_count_df, on=\"redcap_event_name\")\n",
    "\n",
    "# group\n",
    "group_count_df = demo_df.groupby([\"redcap_event_name\"])[\"group\"].value_counts().unstack().reset_index()\n",
    "demo_table_df = pd.merge(demo_table_df, group_count_df, on=\"redcap_event_name\")\n",
    "\n",
    "demo_table_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pheno table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nipoppy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
